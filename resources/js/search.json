[[{"l":"Moreh Documentation Hub","p":["Docker 이미지로 Moreh 실행하기 (moreh-docker-run)","Getting Started (HAC)","GPU 자원 모니터링 (moreh-smi)","GPU 자원 변경 (moreh-switch-model)","HAC Web Console","HAC 관리하기 (Admin Only)","HAC 서버 접속 및 사용하기","HAC(Hyperscale AI Computing)","Kubernetes Cluster에서 Moreh 솔루션 사용하기","Moreh Cloud Platform API","Moreh Model Hub","Platform Cloud Service","Products","Reference Model 학습하기","SMClient 사용하기","Troubleshooting"]}],[{"i":"hac-관리하기-admin-only","l":"HAC 관리하기 (Admin Only)"},{"l":"Admin Documentation","p":["KTC 관리자가 HAC 서버를 효과적으로 관리하고 사용할 수 있도록 SMclient 및 Web Console의 사용을 돕는 것을 목표로 합니다.","HAC Web Console: KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","Moreh SMClient: HAC 환경에서 backnode에 실행되는 worker에 대해서 버전 확인, 토큰 설정 등의 관리를 위한 API입니다.","Moreh API: 오픈 소스 GRPC 기반 API 입니다.","Moreh SMClient 사용하기 문서: moreh_smclient의 기본 사용법을 기술합니다.","HAC Web Console 사용 가이드 는 HAC Web Console로 GPU 자원 모니터링 및 관련 작업 등을 위한 가이드입니다. KTC 관리자가 HAC 클러스터의 자원 사용을 최적화하고 발생 가능한 문제를 빠르게 대응하는데 도움을 줍니다.","Moreh API 접속 및 호출 방법을 소개합니다."]}],[{"l":"Moreh API 사용하기","p":["이 매뉴얼은 Moreh API 접속 및 호출 방법을 소개합니다."]},{"l":"Moreh API 란","p":["Moreh API 는 오픈 소스 GRPC 기반 사용자 API 이며 KT Portal에서 REST로 호출됩니다."]},{"l":"Moreh API 시작하기","p":["Moreh API를 사용하기 위해서는 https://mcp.moreh.dev/ 에서 지정한 KTC 관리자용 아이디와 비밀번호를 입력하면 Moreh API 서비스를 이용할 수 있습니다.","API 호출시 검증된 KTC 관리자용 아이디 및 이메일 주소가 확인이 되는 경우 API 접근 가능 token (access token)이 자동으로 인증됩니다."]},{"l":"API 구성 요소"},{"i":"요청-request","l":"요청 (Request)","p":["먼저 API 요청을 제대로 하기 위해서는 특정 항목들을 일정 포맷에 따라 호출해야 합니다. API 요청 규격을 구성하는 요소는 Method(GET, POST, PUT, DELETE)와 API를 요청하기 위한 파라미터 가 있습니다.","Method","GET","POST","PUT","DELETE"]},{"i":"응답-response","l":"응답 (Response)","p":["응답은 API 요청에 대한 결과값을 의미합니다. 예를 들어 특정 사용자 정보(사용자 고유 Key)를 불러올 때 정상적으로 불러왔는지 결과를 확인할 수 있습니다. 요청한 API의 메서드에 따라 응답 형태는 달라질 수 있는데요. POST 요청 값을 Body에 실어 보낼 때는 해당 값이 잘 저장되었는지, 전달되었는지를 나타내는 성공여부를 나타내기도 하고, GET 요청처럼 특정 정보를 조회하거나 받아올 때는 값들을 코드로 확인할 수 있거나 자동적으로 다운로드 되기도합니다.","요청 성공 시: HTTP 상태 코드 및 API별 성공 응답 필드 반환","요청 실패 시: HTTP 상태 코드 및 JSON 형식의 에러 응답 필드 반환, 에러 응답 필드에 에러 코드 및 메시지 포함"]},{"i":"파라미터query-parameter","l":"파라미터(Query Parameter)","p":["파라미터는 요청 처리에 필요한 데이터를 전달하는 데 사용합니다. 키와 값의 쌍으로 구성되며, 쿼리 스트링(Query string) 또는 바디(Body)를 통해 전달합니다. 각 파라미터는 자료형(Data type)과 필수 전달 여부가 지정돼 있습니다. 이 문서에는 API 메소드 당 전달해야하는 파라미터 type과 필수 여부 설명 등이 제공됩니다. 간혹 Element가 없는 요청도 있는데 정보를 불러올 때 사용하는 GET 메서드에서 Element가 없는 요청이 나타나기도 합니다."]},{"i":"moreh-cloud-apiver-2-information","l":"Moreh Cloud API(ver 2) Information","p":["API Log를 관리합니다.","API 와 DB 상태 및 gRPC 서버와 클라이언트의 통신 상태가 정상적인지 확인합니다.","Backend","Check","DELETE /api/v2/backend- Backend 정보를 삭제합니다.","DELETE /api/v2/backend/group- Backend group 정보를 삭제합니다.","DELETE /api/v2/backend/grouping- Backend의 Grouping 된 것을 해제합니다.","DELETE /api/v2/membership- Membership 정보를 삭제합니다. (Group ID와 Group ID간의 연결을 삭제합니다)","DELETE /api/v2/scheduler/queue- 등록된 Job을 삭제합니다.","DELETE /api/v2/sda- Token 값을 지정하면 해당 SDA를 삭제합니다.","DELETE /api/v2/sdamodel- SDA Model을 삭제합니다.","DELETE /api/v2/sdamodel/group- SDA Model 그룹 정보를 수정합니다.","DELETE /api/v2/sdamodel/grouping- SDA Model의 Grouping을 해제합니다.","DELETE /api/v2/token- Token이 가지고 있는 고유한 값을 입력하면 Token을 삭제합니다.","DELETE /api/v2/token/group- Token (user) 그룹 정보를 삭제합니다.","DELETE /api/v2/token/grouping- Token (user) Grouping을 해제합니다.","GET /api/check- API, IPMI, DB, gRPC 상태 체크. API가 에러일 경우 모두 에러로 표시됨.","GET /api/v2/backend- Backend 정보를 모두 불러옵니다.","GET /api/v2/backend/group- Backend의 group 정보를 불러옵니다.","GET /api/v2/log/sdamanager/event- SDAManager에 발생한 Event(SDA 생성, SDA 변경 등)를 불러옵니다.","GET /api/v2/membership- Membership 정보를 불러옵니다.","GET /api/v2/scheduler/history- GPU 스케줄러의 기록 정보를 불러옵니다.","GET /api/v2/scheduler/queue- GPU 스케줄러의 큐(queue) 안의 정보를 불러옵니다.","GET /api/v2/sda- SDA 정보를 모두 불러옵니다. 할당된 SDA가 존재한다면 할당된 device와 backend 또한 출력합니다.","GET /api/v2/sda/utilizations- SDA의 할당 정보(메모리 사용량, 프로세스 정보)를 불러옵니다.","GET /api/v2/sdamodel- SDA Model 목록(micro, Small, Large, xLarge 등)을 불러옵니다","GET /api/v2/sdamodel/group- SDA Model 그룹 정보를 불러옵니다.","GET /api/v2/token- Token 정보를 모두 불러옵니다.","GET /api/v2/token/group- Token (user) 그룹 정보를 불러옵니다.","GET /api/v2/usage- GPU 사용 기록을 불러옵니다.","GPU 사용 기록을 확인합니다.","GPU 스케줄러의 대기상태(queue)와 할당 기록을 확인합니다.","Log","Membership","POST /api/v2/backend- Backend 정보를 생성합니다.","POST /api/v2/backend/group- Backend group 정보를 생성합니다.","POST /api/v2/backend/grouping- Backend ID를 지정하여 Device들의 Status를 변경합니다.","POST /api/v2/membership- Membership 정보를 생성합니다. (Group ID와 Group ID간의 연결을 생성합니다.","POST /api/v2/sda- SDA Model, Token, 고정할당유무, 별칭을 지정하면 SDA를 생성합니다.","POST /api/v2/sdamodel- SDA Model 을 추가합니다.","POST /api/v2/sdamodel/group- SDA Model 그룹 정보를 생성합니다.","POST /api/v2/sdamodel/grouping- SDA Model의 Grouping을 생성합니다.","POST /api/v2/token- Token 별칭을 입력하면 고유한 값을 가진 Token을 생성합니다.","POST /api/v2/token/group- Token (user) 그룹 정보를 생성합니다.","POST /api/v2/token/grouping- Token (user) Grouping을 생성합니다.","PUT /api/v2/backend- Backend 정보를 수정하거나 전원 원격 제어를 위해 IPMI 명령어를 실행합니다.","PUT /api/v2/backend/device/status- Backend ID를 지정하여 Device들의 Status를 변경합니다.","PUT /api/v2/backend/group- Backend group 정보를 수정합니다.","PUT /api/v2/backend/grouping- Backend로 이루어진 Group들 간에 관계를 수정합니다.","PUT /api/v2/scheduler/queue- 큐에서 대기중인 GPU 작업의 순서를 바꿀 때 사용합니다.","PUT /api/v2/sda- Token 값을 지정하고 SDA Model ID를 선택하면 Token의 SDA Model이 지정된 값으로 수정합니다.","PUT /api/v2/sdamodel/group- SDA Model 그룹 정보를 수정합니다.","PUT /api/v2/token- Token이 가지고 있는 고유한 값을 입력하면 Token을 수정합니다.","PUT /api/v2/token/group- Token (user) 그룹 정보를 수정합니다.","Scheduler","SDA","SDAModel","Token","Token 및 Group 정보를 관리합니다.","Token 별 사용 가능한 AI 가속기 디바이스(SDA)를 관리합니다.","Usage","사용 가능한 AI 가속기 디바이스(SDAModel)를 관리합니다.","사용자 툴(moreh-smi)에서 넘어오는 backend 정보(SDA 및 token, 학습 process 정보)들을 관리합니다."]}],[{"l":"HAC Web Console 사용 가이드","p":["이 문서는 HAC Web Console로 GPU 자원 모니터링 및 관련 작업 등을 위한 가이드입니다. KTC 관리자가 HAC 클러스터의 자원 사용을 최적화하고 발생 가능한 문제를 빠르게 대응하는데 도움을 줍니다.","HAC Web Console Overview","Web Console Components","Cluster List","Admin User Manage","Notification Manage","Home GPU 모니터링","Global 모니터링","Job & History","HAC 사용자 계정 관리","SDA 모델 관리","클러스터 설정"]},{"l":"1. HAC Web Console 서비스 개요","p":["HAC Web Console은 KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","HAC Web Console을 사용하면 KTC 관리자는 다음과 같은 기능을 활용할 수 있습니다:","실시간 GPU 상태 모니터링: 서버 상태와 노드별 동작 여부를 확인하고, GPU의 가용성 및 예약 현황을 실시간으로 쉽게 파악할 수 있습니다. 또한, GPU 관련 작업 로그를 통해 성능 이슈나 문제를 신속하게 분석할 수 있습니다.","개발자의 니즈에 따라 GPU 자원 조정 가능: GPU 자원 분배에 관한 상태 값을 사용자의 편의와 요구에 따라 다양하게 조정할 수 있으며, 원활한 서비스 제공을 위해 필요한 조치를 즉시 취할 수 있습니다.","위 제공된 기능들을 통해 KT Cloud 관리자는 GPU 리소스를 효율적으로 관리하고, 클러스터의 안정성을 바탕으로 사용자들에게 원활한 서비스를 제공할 수 있습니다.","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬에서 가장 적합한 사용자 경험을 제공합니다."]},{"l":"2. Web Console Components","p":["Admin User Manage (관리자 정보 변경 및 권한 설정하기)","Cluster List","Global 모니터링","GPU 클러스터의 상태 및 실시간 사용 정보를 지표로 나타냅니다.","HAC GPU 사용을 위한 전용 관리 페이지입니다.","HAC 사용자 관리","Home GPU 모니터링","Job & History","Notification Manage (전체 알림 관리하기)","SDA 모델 관리","Web Console의 요소들과 각 기능을 어떻게 사용할 수 있는지 설명합니다.","각 클러스터 당 모레 솔루션의 버전을 관리할 수 있습니다.","각 클러스터에 포함된 모든 HAC 사용자 정보(사용자 그룹 수, 누적 사용량, 전체 SDA 개수 등)를 제공합니다.","각 클러스터에서 HAC 사용자에게 제공되는 SDA Model을 관리할 수 있습니다.","각각의 클러스터에 포함된 GPU 자원의 종합적인 모니터링이 가능하며 HAC 사용자에게 제공되는 GPU를 관리할 수 있습니다.","어떤 페이지에서든 빠르게 전체 GPU 클러스터에 포함된 GPU Node 들의 상태를 모니터링할 수 있습니다.","클러스터 내 GPU를 사용하는 작업을 관리하고 작업 진행 상황과 작업에 관련된 로그 및 세부사항을 확인할 수 있습니다.","클러스터 설정"]},{"l":"1. Cluster List","p":["✔️Master 권한의 관리자만 새로운 Admin 계정을 추가할 수 있습니다.","Admin User List 상단의 [+ Add] 버튼을 클릭하면 Modify Personal Info(Admin 개인 정보 수정) 모달과 동일한 모달이 아래와 같이 등장합니다. 모달에 추가할 관리자 정보를 입력합니다.","Admin User List에서 특정 관리자의 첫번째 Interaction 아이콘을 클릭하면 관리자에 대한 정보를 수정할 수 있습니다. Master 계정의 사용자는 계정(General, Master 모두)에 대한 정보를 수정 가능 하며, General 계정의 사용자는 개인 계정 정보만 수정 가능합니다.","Admin User Manage (관리자 개인 정보 변경 및 권한 설정하기)","Admin 관리자 계정 추가하기","Cluster List 는 HAC Web Console의 모든 클러스터에 대한 통합 개요 정보와 특정 클러스터의 세부 정보(패키지 배포 서버 상태, SDA Manager 상태, GPU의 클러스터 사용률 등)를 제공합니다.","Cluster 이름, IP 주소는 필수 입력 항목입니다.","Cluster 추가하기","General 계정 : 개인 계정 정보만 수정 가능","GPU 디바이스 온도가 86~ 93°C인 경우 주의 단계 알림","GPU 디바이스 온도가 94~ 97°C인 경우 경고 단계 알림","GPU 디바이스 온도가 98~°C인 경우 조치 단계 알림","GPU 부족","GPU 에러","GPU 온도","Master 계정 : Moreh에서 직접 만들어서 제공하는 계정이며 General, Master 계정 모두 생성과 수정 가능","Master 권한, General 중 선택합니다.","Notification Manage (전체 알림 관리하기)","Notification Manage 페이지의 Notification List(클러스터 알람 목록)에 [+ Add Filter] 버튼을 클릭하면 다음 필터 패널이 나타납니다. 알림 특정 태그를 추가/제외 가능합니다.","Untitled","개별 클러스터 삭제 시 확인 모달에서 [삭제] 버튼 클릭","관리자 ID","관리자 권한","관리자 이름 (필수 입력 사항)","권장사이즈: 120px(width) * 120px(height) 또는 1:1 비율","두번째 Interaction 아이콘을 클릭하면 해당 관리자의 권한을 General/Master로 변경할 수 있습니다. ✔️Master 권한의 관리자만 변경 가능합니다.","로그인 인증 정보로 로그인하여 HAC 웹콘솔에 접속하면 첫 페이지가 다음과 같이 표시됩니다.","메일 주소이며 한 번 생성된 후에는 변경 불가능합니다.","모니터링할 특정 기간에 대해 년, 월, 일 시간으로 시작 날짜와 종료 날짜를 입력합니다.","물리 GPU에 에러가 발생한 경우","비밀번호 (필수 입력 사항)","사용자 관리 페이지에서 왼쪽 사이드바의 [Permission Manage]를 클릭하면 아래와 같이 Admin User List가 나타납니다. Admin User List에는 사용자 프로필 아이콘, 관리자 ID, 관리자 이름, 권한 Type 정보와 Master 권한의 관리자가 상호작용가능한 아이콘이 제공됩니다.","상단 우측의 [Notification Manage] 버튼 과 [Admin User Manage] 버튼 을 클릭한 후 각 알람 관리 페이지와 Admin 사용자 관리 페이지로 이동하여 Admin 사용자 개인정보와 권한 및 웹콘솔의 모든 알림과 Admin 사용자를 관리할 수 있습니다.","선택 사항이며 미입력시 디폴트 아이콘이 제공됩니다.","세번째 휴지통 모양의 Interaction 아이콘을 클릭하면 해당 관리자를 삭제할 수 있습니다. ✔️Master 권한의 관리자만 삭제 가능합니다.","아래 모달 창이 뜨면 추가할 클러스터 정보(이름, IP 주소, Description)를 입력합니다.","아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","알림리스트 중 모니터링할 클러스터를 선택 가능합니다.","영문, 숫자 또는 대문자 포함 제한이 없습니다.","웹 콘솔의 첫 화면에서 아래 클러스터 추가 [+ ADD Cluster] 아이콘을 클릭합니다.","이 페이지에서 클러스터의 개요 정보를 확인하고, 클러스터 목록을 통해 개별 클러스터로 진입할 수 있습니다. 또한 관리자 계정의 개인정보와 권한을 설정할 수 있습니다.","작업 에러","제공되는 알림 분류 중 선택 가능합니다.","진행 중이던 작업이 에러가 발생하여 멈춘 경우","클러스터에 배정된 GPU 자원이 부족하여 대기열 속 다음 작업을 진행하지 못하는 경우","프로필 사진"]},{"l":"2. Home GPU Monitoring","p":["(예시) Group A 클러스터에 등록된 A100, V100, MI250 세 종류가 있을 경우 GPU 디바이스 종류의 개수: 3개 로 표현","00~05 로 그룹핑되어있는 부분이 같은 사용자가 사용하는 노드입니다. 그룹핑된 부분에 마우스 오버시 해당 디바이스 묶음을 사용하는 토큰에 대한 정보가 툴팁으로 제공됩니다.","00번 부터 07번까지 각 GPU 디바이스로 구분","Add Filter를 적용할 경우 선택된 필터링 내용을 해시태그 형태로 제공합니다.","CPU 온도와 노드 메모리 사용률 정보","Description (Cluster 추가 시 Admin 관리자가 입력한 노드 사용 관련 내용 )","GPU 디바이스 종류의 개수","GPU 디바이스의 사용 현황이 색상으로 표현됨","GPU 메모리 정보","GPU 정보","GPU 종류","GPU 현재 상태를 다음 3가지로 구분하여 선택된 상태에 해당하는 노드가 필터링 결과로 제공됩니다.","Grid(바둑판 뷰)의 노드 1개의 이미지","HAC Web Console 효율성 (Service Efficiency)","Node - Grid 에서 노드 1개의 정보는 아래와 같이 나타납니다.","Node Group","Node Group List 우측 상단에 [+ Add] 버튼을 클릭한 후 아래 모달에서 필요한 정보를 입력합니다.","Node Group 이름","Node Group은 다음 정보를 제공합니다.","Node List 에서 모니터링 리스트에서 제공하는 노드 정보는 위 Node - Grid(바둑판 뷰)의 셀과 동일합니다.","Node Monitor","Node 개수와 GPU 자원의 양으로 나타냄","Overview 클러스터 개요","Screen Shot 2023-07-30 at 4.19.00 PM.png","SDA Manager 상태 (원활/불량)","Untitled","User","그룹에 대한 설명","노드 그룹","노드 그룹 이름 (필수 입력 사항)","노드 그룹 추가하기","노드 목록에 필터링 적용하기","노드 이름 (호스트 이름)","노드가 소속된 GPU 디바이스 그룹","대기중 (Idle)","리스트 우측 상단에 다음 [+ Add Filter] 버튼을 클릭하여 아래 모달에 노드 목록에 표시될 항목을 선택합니다.","링크 클릭시 HAC 사용자 관리 페이지로 이동합니다.","모니터링 리스트는 Grid(바둑판 뷰)와 List(목록형 뷰)로 제공되며 사용중인 노드와 이름 순서로 정렬됩니다.","빨간색 - 사용 불가 (Shutdown)","사용 가능한 노드 개수","사용 불가 (Shutdown)","사용중 (Processing)","사용중인 Node 개수와 GPU 자원의 양을 전체 대비 백분율로 나타냄","삭제","상호작용","선택된 노드리스트","설명","수정","연관된 SDA 모델 그룹","전일 기준으로 1주일 동안 평균 사용한 노드 수와 GPU 디바이스 수 (전체 대비 백분율)","전체 노드 그룹, Group A, Group B, Group C에 해당하는 노드가 필터링 결과로 제공됩니다.","전체 노드 중 사용 불가능한 노드와 GPU 자원의 양을 전체 대비 백분율로 나타냄","전체 사용자 계정이 선택한 SDA Model의 GPU 자원의 총합 / 평균 사용중인 GPU 자원의 양 = %","전체 사용자 계정이 제공되며 특정 계정을 추가하거나 제외할 수 있습니다.","초록 - 사용중 (Processing)","최상단 디바이스 번호에 토큰 포함관계가 표현","클러스터에 포함된 전체 노드 리스트와 선택된 노드 리스트가 제공되며 검색, 체크박스 선택 등을 통해서 상호작용이 가능합니다.","특정 노드 이름 혹은 그룹이름에 대해 검색창에 찾아볼 수 있습니다.","패키지 배포 서버 상태 (원활/불량)","평균 사용 중인 노드 수","포함된 노드 개수","포함된 디바이스 종류","해당 디바이스 메모리의 현재 온도와 사용률을 나타냄","해당 클러스터를 사용중인 HAC 사용자 계정 개수","해당 클러스터에 포함되어 있는 전체 노드 수","현재 클러스터에서 사용 불가능한 노드 수","현재 클러스터에서 사용 중인 노드 수","현재 해당 클러스터에 등록된 물리적인 GPU 제품 종류의 개수","현재 해당 클러스터에 존재하는 사용자가 설정한 GPU 종류에 따라 필터링 가능하며 체크 박스 형태로 여러개 선택 가능합니다.","호함된 노드 수","회색 - 대기중 (Idle)"]},{"l":"3. Global 모니터링","p":["Global Monitoring 페이지는 사용자가 HAC Web Console 내부에서 전체 클러스터를 빠르게 시각적으로 모니터링할 수 있도록 도와주는 패널입니다. 로컬 화면의 좌측 Navigation 바 하단에 위치한 글로벌 모니터링 아이콘을 클릭하면 다음 페이지가 나타납니다.","Global Monitoring 페이지의 전체 클러스터 개요와 각 클러스터는 다음과 같은 정보를 포함합니다.","Overview - All Clusters (클러스터 개별 개요)","SDA Manager서버","Untitled","노드들 중 간혹 두 명 이상의 HAC 사용자가 하나의 노드를 나누어서 사용하는 경우가 있습니다.","따라서 하나의 노드를 두 명 이상의 HAC 사용자가 사용하는 경우에는 해당 노드에 마우스 오버 시 아래 툴팁 이미지와 같이 사용중인 노드 이름과 현재 상태(Processing/Idle/Shutdown), 사용시간, GPU index 번호, 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 나타납니다.","빨강 Shutdown - 해당 노드를 사용했던 사용자 계정 정보와 셧다운된 시각","사용 가능한 노드 수","사용 불가능한 노드 수","사용중인 노드 수","서비스 효율성","이런 경우 노드에 마우스 오버 시 나오는 정보 툴팁도 해당 노드를 사용하는 HAC 사용자가 한명일 때와 여러 명일 때가 구분됩니다. 예를 들어 3개의 노드와 4개의 GPU를 사용하는 경우 해당 HAC 사용자가 사용하는 3개의 노드에 마우스 오버하면 한 명의 유저에 대한 툴팁만 나오겠지만, 4번째 노드인 GPU 4개를 사용하는 노드에 마우스를 오버하면 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 툴팁에 제공됩니다. 또한 툴팁에 제공되는 모든 엔드유저가 사용 중인 노드 시각화 또한 하이라이트 됩니다.","전체 노드 수","초록 Processing - 해당 노드를 사용하는 사용자 계정 정보와 사용시간","클러스터 모니터링","클러스터의 각 노드에 마우스 오버시 현상태에 따라 아래 정보가 제공됩니다.","패키지 배포 서버","평균 사용 노드 수","하나의 노드를 여러명의 HAC 사용자 사용했을때 툴팁","하나의 노드를 한명의 HAC 사용자 사용했을때 툴팁","회색 Idle - 해당 노드가 포함된 GPU 그룹 정보"]},{"i":"4-job--history","l":"4. Job & History","p":["Framework (사용 프레임워크 버전)","GPUs (SDA Model 이 사용중인 GPU 개수)","History List (작업 히스토리)","History List에는 가장 최근에 종료된 작업순으로 정렬됩니다.","Id (아이디)","Interaction (상호작용 아이콘 - 우선순위 변경하기, 특정 작업 취소하기)","Job List (작업목록)","Job Priority (작업 우선순위)","Job 목록에 사용자가 요청한 작업은 사용자의 우선순위에 해당되는 기본값을 가지고 들어오며, 만약 작업이 대기열에 들어가게 되면 해당 우선순위 값을 첫 번째 정렬 값으로 사용하여 대기열에 적용됩니다. 이렇게 정렬된 대기열(Queue)에 있는 각 작업의 우선순위를 수동으로 변경할 수 있습니다.","MAF ver (모레 솔루션 버전)","Overview (작업 개요)","Queued-> 클러스터에 해당 작업에 필요한 GPU가 부족하여 진행중이지 못한 작업","Request Time (작업 요청된 시간)","Running -> 현재 진행중인 작업으로 GPU 사용중","Running Time (진행 시간)","Start Time (시작 시간)","Status (현재 상태)","Untitled","Untitled-8.png","User (사용자)","Waiting Time (대기중인 시간)","개별 Job 항목을 클릭하면 확인할 수 있는 작업 로그","개별 클러스터에서 GPU를 사용하여 해당 클러스터에서 진행중인 작업(Job)과 작업 히스토리를 확인하고 GPU 배정이 필요한 작업 간의 우선 순위를 조정하여 먼저 할당 받을 수 있는 페이지입니다. 작업 목록에서 개별 작업 항목을 클릭하면 세부 로그를 확인할 수 있는 페이지로 이동합니다.","리스트에서 각 작업의 우선순위 변경 아이콘을 클릭하면 모달을 통해 작업 우선순위 변경이 가능합니다.","사용자 Job 대기열 우선순위 설정하기","사용자 계정 별로 기본 우선순위가 있으며 Queue에서 우선순위가 가장 높은 Job이 먼저 GPU 노드를 할당 받을 수 있습니다.","시,분, 일 변화 단위로 따라가기 (사용한지 25시간 -> 1D 1H 로 표기)","우선순위 값(-99~ 99 사이의 정수)이 99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당 됩니다.","작업 목록에는 다음 정보가 표시됩니다.","작업 우선순위(Priority)","작업 우선순위는 Job Queue에서 대기중인 Job중에서 할당받는 순서를 결정합니다.","전체 노드 혹은 노드 별로 확인이 가능합니다.","전체적으로 작업 목록(Job List)와 동일한 값을 제공하며 상태값(Status)만 Completed(완료), Expired(HAC사용자 또는 Admin의 input 없이 모종의 에러로 종료), Canceled(HAC 사용자가 수동으로 종료) 로 제공됩니다.","해당 작업이 가지는 고유 ID 정보","현재 사용 가능한 디바이스와 에러가 발생한 작업수 등을 표시됩니다."]},{"i":"5-end-userhac-사용자-관리하기","l":"5. End User(HAC 사용자) 관리하기","p":["-99~ 99 사이의 숫자로 설정","-99~ 99사이의 숫자 (default=0)","(default = not selected)","99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당됩니다.","Admin 사용자가 지정한 HAC 사용자 그룹","default value = 0","default value = 1","GPU 사용 안하는중","GPU 사용중","GPU 작업 대기중","HAC 사용자 SDA 번호","HAC 사용자 그룹 이름","HAC 사용자 정보 삭제하기","HAC 사용자 추가하기","HAC 사용자에게 제공되는 SDA의 고유 ID","HAC 사용자에게 허용되는 SDA 개수","Key-Value 쌍으로 입력합니다.","Max Multi Use: 1개의 SDA로 n 번 GPU를 할당할 때 n 의 최대값","MAX SDA","Max SDA = 1 인 경우 Max Multi Use 활성화","Max SDA = 1 인 경우에만 사용 가능합니다.","Max SDA 1 인 경우 Max Multi Use 비활성화","MAX SDA 수","Max SDA 수 (필수 입력사항)","Overview (전체 유저 개요 정보)","SDA Model * N","SDA Model 설정","SDA 추가하기","Untitled","User Group List","User List (사용중 - 대기중 순서로 정렬)","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 정보를 수정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 환경변수를 설정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 Key 와 Value 값을 입력합니다.","User List에 새로운 HAC 사용자를 추가하려면 우측 상단에 **[+ Add User]** 버튼을 클릭 후 아래 모달에서 다음 정보를 입력합니다.","User Manage 페이지에서는 사용자 관리 페이지에서는 해당 클러스터에 포함된 모든 HAC 사용자를 관리할 수 있습니다. 상단에 있는 전체 유저 개요 정보와 하단의 User List(사용자 목록)이 제공됩니다.","User Name","값이 1이 아닌경우 해당 MAX SDA 값만 제공됩니다.","값이 1인 경우 허용된 Multi Use 값이 제공됩니다.","그룹 삭제","그룹 수정","누적 사용량 (Total Usage)","사용자 계정 정보 변경하기","사용자 그룹 목록은 다음과 같은 정보로 구성됩니다.","사용자 그룹 설정하기","사용자 그룹 수","사용자 삭제","사용자 우선순위","사용자 이름 (User)","사용자 이름 (필수 입력 사항)","사용자 정보 변경시 아래 정보를 입력합니다.","사용자 정보 편집","사용자 환경변수 설정","사용자 환경변수 설정하기","사용자가 작업을 시작하면 해당 작업에 우선순위가 부여되며, 이 우선순위는 작업 목록에서 사용자 우선순위와 별개로 조정할 수 있습니다. (기본 값 = 0)","사용중인 SDA Model","상호작용 아이콘","설명","소속 그룹 (User Group)","여러 Key-Value 쌍을 추가할 수 있으며 한 번 입력한 환경변수를 삭제할 수 있습니다.","연관된 SDA Model Group","우선 순위 (Priority)","작업 우선순위는 기본 값(0)과 작업 목록에서 조정 가능한 값으로 구분됩니다.","전체 SDA 수","전체 유저 수","좌측 휴지통 모양 아이콘을 클릭해서 사용자 정보를 삭제할 수 있으며 삭제 후에는 기본 정보를 불러올 수 없습니다.","총 누적 사용량 (GPU를 사용한 시간)","최근 실행 시간 (Recent Use)","하단의 SDA Model 선택은 한 개만 가능하고 추가 버튼 비활성화","하단의 드롭다운 버튼을 클릭해서 max SDA에서 설정한 N개의 SDA Model 추가 가능","해당 HAC 사용자 그룹과 매칭된 SDA Model Group","해당 그룹에 포함된 사용자 수","현재 상태"]},{"l":"6. SDA Model 관리하기","p":["** SDA(** Software-Defined Accelerator) Model: 엔드유저가 사용하는 GPU의 단위이며 하나의 사용자 계정에 종속됩니다.","Interaction 버튼 클릭시 다음과 같은 일을 수행할 수 있습니다.","Interaction 아이콘 (SDA Model 삭제)","SDA Model Group","SDA Model Group List의 Interacton에 해당하는 두번째 아이콘을 클릭해서 해당 SDA Model그룹과 1:1로 매칭되는 노드 그룹을 선택할 수 있습니다.","SDA Model Group List의 Interacton에 해당하는 세번째 아이콘을 클릭해서 SDA Model 정보에 해당하는 Node Group 이름, SDA Model, Group Description 등을 수정할 수 있습니다.","SDA Model Group List의 Interacton에 해당하는 첫번째 아이콘을 클릭해서 해당 SDA Model그룹과 1:1로 매칭되는 사용자 그룹을 선택할 수 있습니다.","SDA Model Group 페이지로 이동합니다.","SDA Model Group: 그룹 기능은 고객의 토큰에 따라 사용할 수 있는 AI 가속기 디바이스와 그 수를 편리하게 제어하는 기능입니다. 예를 들어, A 고객은 Small과 Medium만 사용하도록 설정된 SDAModelGroupA에 연결됩니다. B 고객은 Medium부터 Large와 xLarge까지 옵션을 선택할 수 있도록 제한을 설정됩니다. 이렇게 그룹 기능을 통해 유연하게 GPU 자원을 조절할 수 있게 됩니다.","SDA Model List","SDA Model 관리 패널에서는 해당 클러스터에서 사용자에게 제공되는 SDA Model 및 SDA Model 그룹을 추가, 변경, 삭제할 수 있습니다.","SDA Model 그룹 Node 그룹과 매칭하기","SDA Model 그룹 변경하기","SDA Model 그룹 사용자 그룹과 매칭하기","SDA Model 그룹 선택","SDA Model 그룹명","SDA Model 그룹을 Node 그룹과 매칭하면 사용할 수 있는 GPU 노드 수를 쉽고 유연하게 관리할 수 있습니다.","SDA Model 그룹을 사용자 그룹과 매칭하면 HAC 사용자인 고객의 계정에 따라 사용할 수 있는 AI 가속기 디바이스와 그 수를 제어할 수 있습니다. 예를 들어, A 고객은 Small (노드를 4개 까지만 사용할 수 있는 SDA Model)과 Medium만 사용하도록 설정된 SDA Model 그룹A에 연결됩니다. B 고객은 Medium부터 Large와 xLarge까지 옵션을 선택할 수 있도록 제한을 설정됩니다. 이렇게 그룹 기능을 통해 유연하게 GPU 자원을 조절할 수 있게 됩니다.","SDA Model 명","SDA Model 명 입력","SDA Model그룹과 1:1로 매칭되는 디바이스 그룹을 선택합니다.","SDA 모델 그룹 추가하기","Untitled","구성 노드 수 (+gpu수)","그룹 설명","노드 그룹 매칭","노드 수 선택","드롭다운에서 SDA Model 선택","마우스 오버시 툴팁으로 포함 모델 리스트를 제공합니다.","모델 목록 패널 상단 우측에 있는 [+ Add] 버튼을 클릭하여 아래와 같은 모달에서 해당 정보를 입력합니다.","사용자 그룹 매칭","삭제할 SDA Model의 좌측 휴지통 모양 아이콘을 클릭해서 해당 SDA Model을 삭제할 수 있습니다. **** 삭제 후에는 이전 정보를 검색할 수 없으며 영향을 받는 작업이 있을 수 있습니다.","소속 SDA Model 그룹","아래 모달에서 SDA Model그룹과 1:1로 매칭되는 GPU 자원을 배분하는 디바이스 그룹을 선택합니다.","우측 상단에 [+ Add]버튼 클릭 후 아래 모달에서 다음 정보를 입력합니다.","특정 SDA 그룹 삭제","특정 SDA 그룹 수정","포함 모델 수"]},{"l":"7. 클러스터 설정하기","p":["Cluster Setting 페이지로 이동합니다.","Cluster Setting 페이지에서는 현재 클러스터에서 제공되는 모레 솔루션 버전 리스트를 제공하여 모레솔루션 버전을 관리할 수 있습니다.","MAF Ver List","MAF Ver List 에서 두번째 Interaction 아이콘을 클릭하면 HAC 사용자가 사용할 수 있는 최신버전으로 설정할 수 있습니다.","MAF Version (최신 버전인 경우 옆에 아이콘이 표기됩니다)","Overview (Cluster 개요)","Path","Untitled","마프 버전의 현재 상태","모레 솔루션 버전 정보 수정","모레 솔루션 버전 정보 수정하기","모레 솔루션(MAF) 버전을 구성하는 아래 정보를 입력한 후 버전 수정을 클릭합니다.","비활성화","비활성화된 MAF 버전 개수","사용 가능한 MAF 버전 개수","사용중 (green)","삭제","삭제 대기중 (yellow)","상호작용 (특정 버전 관리하기)","수정","전체 MAF 버전 개수","최신 버전 설정하기","해당버전보다 윗 버전은 자동으로 비활성화됩니다.","활성/비활성화","활성화 버튼 클릭시 다시 활성화 가능"]},{"l":"트러블슈팅","p":["GPU 디바이스 온도가 86~ 93°C인 경우 주의 단계 알림","GPU 디바이스 온도가 94~ 97°C인 경우 경고 단계 알림","GPU 디바이스 온도가 98~°C인 경우 조치 단계 알림","GPU 부족","GPU 부족 문제는 다른 작업이나 사용자가 GPU 자원을 과도하게 사용하고 있어서 여유 자원이 부족하거나 메모리 누수 및 냉각 시스템(환기 부족), GPU 드라이버나 관련 설정 문제등 복합적인 요소가 GPU 부족 및 GPU 온도 알림의 원인일 수 있습니다.","GPU 에러","GPU 온도","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬(Chrome)에서 가장 적합한 사용자 경험을 제공합니다. https://mcp.moreh.dev/ 로 접속하여 제공받은 아이디 패스워드를 입력합니다.","HAC 서버상의 자세한 원인을 해결하고 파악하기 위해서는 고객지원을 요청 주시기 바랍니다.","Q. 사용자 계정 별로 최대 GPU 자원의 양(SDA 개수)을 제한하려면 어떻게 해야 하나요?","Q. 웹콘솔을 어떻게 접속하나요?","User Management 페이지에서 Max SDA 수를 제한하고자 하는 해당 Token을 클릭한 후 사용가능한 최대 SDA 개수를 입력합니다.","물리 GPU에 에러가 발생한 경우","아래 알람 중 GPU 부족 알람이 뜨는 경우 해당 Job과 관련된 에러의 세부 로그를 확인하면 종종 문제의 근본 원인을 찾는 데 도움이 됩니다. Job & History 페이지 에서 개별 작업 항목을 클릭하면 세부 로그 파일을 분석하여 문제 발생 시간, GPU 자원 사용에 관한 작업 및 오류 메시지를 확인할 수 있습니다.","웹콘솔에서 GPU 부족 or GPU 온도알람이 뜨는데 정확한 원인을 파악하고 해결할 수 있는 방법은 무엇인가요?","클러스터에 배정된 GPU 자원이 부족하여 대기열 속 다음 작업을 진행하지 못하는 경우"]}],[{"l":"SMClient 사용하기"},{"i":"smclient-란","l":"SMClient 란?","p":["KT HAC 서비스의 SMClient는 SDAManager API를 호출하는 관리자 tool입니다. 대표적인 기능으로 (1) HAC 서비스 사용 현황 조회, (2) 토큰에 대한 관리, (3)user group, SDAModel group, Backend group 및 멤버쉽에 대한 관리가 있습니다."]},{"l":"1. SMClient 실행하기","p":["SDAManager 의 클라이언트인 moreh_smclient 는 다음과 같이 실행할 수 있습니다. 현재 SDAManager 의 상태나 정보를 체크할 때 사용하게 됩니다. moreh_smclient를 실행하려면 SDAManager에 연결할 수 있도록 ip, port의 환경 설정이 필요합니다."]},{"l":"2. 사용 현황 조회"},{"l":"A. 전체 노드 및 디바이스 사용 현황 조회","p":["show backend 명령어를 사용하여 moreh_smclient로 해당 클러스터에서 사용되는 노드와 디바이스 정보를 조회할 수 있습니다.","출력되는 조회 정보는 다음과 같습니다. - Name: 노드의 이름 - IP: 노드의 ip address - Status: 노드의 상태 정보 - SHUTDOWN: 노드 사용 불가 - ACTIVE: 노드 사용 가능 - Device: 디바이스(GPU)의 갯수와 상태 정보 - SHUTDOWN: 디바이스 사용 불가한 상태 - IDLE: 디바이스 사용 가능 - PREPARING: 할당 된 디바이스 사용 준비 - PROCESSING: 디바이스 사용 - CLEANING: 사용된 디바이스 정리","사용 예시"]},{"l":"B. 현재 실행 또는 대기 중인 작업 조회","p":["show job 명령어를 실행하여 moreh_smclient로 실행 중 또는 대기중인 작업 정보를 조회할 수 있습니다.","출력되는 조회 정보는 다음과 같습니다.","FeID: Job의 id","Token: 실행한 Token","PRY: Job의 우선순위 값 (기본값 : 0)","Status: Job의 상태정보","PID: 해당 vm에서의 pid","Process Name: 실행한 process 및 매개변수 정보","사용 예시"]},{"l":"C. 작업 상세 조회","p":["Backend Group: 해당 vm이 속한 backend group 이름","Client PID: 해당 vm에서의 pid","Client: 해당 vm에서 사용하는 moreh 솔루션 버전","Device Count: GPU 갯수","Device Information: 연결된 노드 및 디바이스 정보 (출력 예 - back10 | 0,1,2,3,4,5,6,7)","Frontend ID: Job의 id","moreh_smclient를 이용하여 실행 또는 대기중인 작업에 대해서 상세한 조회할 수 있습니다.","Priority: Job의 우선순위 값 (기본값 : 0)","Process Name: 실행한 process 및 매개변수 정보","Request Time: 작업 요청 시간","SDA: Token에 별도로 지정된 SDA ID 정보","Start Time: 작업 시작 시간 (대기 및 준비 시간을 제외한 실제 GPU 연산시작 시간)","Status: Job의 상태정보","Token Name: Token 정보","Token: 실행한 Token","Version: 해당 vm의 클라이언트 버전","명령어는 get job feid {id} 또는 get job token {token} 이며 조회되는 정보는 다음과 같습니다.","사용 예시"]},{"l":"D. 대기중인 작업에 대한 우선순위 변경","p":["update job priority {id} {value} 명령어를 사용하여 대기중인 작업의 우선순위를 변경할 수 있습니다.","입력시 사용되는 매개변수는 다음과 같습니다.","id: 작업의 id","value: 변경하고자 하는 우선순위 값"]},{"l":"E. 실행 또는 대기 중인 작업에 대한 강제 취소","p":["release {id} 또는 release {token} 명령어를 사용하여 실행 또는 대기 중인 작업에 대한 강제 취소가 가능합니다.","입력시 사용되는 매개변수는 다음과 같습니다.","id: 작업의 id","token: 사용자 token 값"]},{"l":"3. Token 및 SDA 관리하기"},{"l":"A. Token 및 SDA 생성하기","p":["기본적인 Token 생성(발급) 및 삭제 방법은 moreh-smclient에서 명령어 help 를 입력하면 다음과 같이 출력됩니다.","create token 이라는 명렁어로 token을 생성할 수 있는데 이때 으로 되어 있는 부분이 token name 입니다.","Token 생성 및 SDA 설정 예시","Token을 먼저 생성하고 반환 받은 token으로 SDA를 생성합니다. SDA를 생성할 때는 model 값을 함께 주어야 합니다. SDA 생성시 넣는 숫자는 model의 id입니다.","sdamodel 의 ID는 show sdamodel 이라는 명령어로 확인할 수 있습니다.","Tip","모든 명령어는 한줄 명령으로 실행 가능합니다."]},{"l":"B. Token 삭제하기","p":["Token을 삭제하기 위해서는 먼저 SDA를 삭제해야 합니다.","명령어","delete sda: SDA 삭제 (usages: delete sda )","delete token: Token 삭제 (usages: delete token )","Tip","한줄 명령으로 실행 가능합니다."]},{"l":"C. Token의 우선순위 변경","p":["update token priority {token} {priority} 명령어를 사용하여 고객사 token의 우선순위를 변경할 수 있습니다. 예를 들어 작업 Queue에 A고객(48노드), B고객(0.5노드), C고객(0.5노드), etc. 가 있을 때 대형 고객 A가 가장 앞에 있을 경우에는 B와 C고객은 못 들어가게 됩니다. 이때 대형 고객 A의 Token 자체의 priority를 낮게 조정해두고, B, C 고객 priority를 높게 해 두면 항상 B, C 고객이 수행하는 작업은 대형 고객 A가 만든 job 보다 항상 먼저 들어갈 수 있게 됩니다.","priority 값이 높은 token의 작업이 먼저 할당되며, priority 가 동일할 경우에는 먼저 요청된 token이 수행됩니다.","입력시 사용되는 매개변수는 다음과 같습니다.","token: 실행한 Token 정보","priority: 변경하고자 하는 우선순위 값"]},{"l":"D. Token 환경 변수 추가하기","p":["토큰에 환경 변수를 추가하는 경우 get token {token} 으로 현재 토큰에 반영된 환경 변수를 확인합니다.","add token env {token} {env_key} {env_value} 명령어를 사용하여 토큰에 환경 변수를 추가 할 수 있습니다.","입력시 사용되는 매개변수는 다음과 같습니다.","token: 추가 할 대상의 token 정보","env_key: 환경 변수","env_value: 환경 변수 설정에 필요한 값"]},{"l":"E. Token 환경 변수 삭제하기","p":["remove token env {token} {env_key} 명령어를 사용하여 토큰에 환경 변수를 삭제 할 수 있습니다.","입력시 사용되는 매개변수는 다음과 같습니다.","token: 추가 할 대상의 token 정보","env_key: 환경 변수"]},{"l":"F. Token에서 multi SDA 최대 개수 설정하기","p":["multi SDA를 사용 시, 동시에 사용할 수 있는 multi sda 개수의 최댓값을 설정할 수 있습니다.","update token sda max {token} {max} 명령어를 사용하여 토큰에 multi sda 개수의 최댓값을 설정합니다.","입력시 사용되는 매개변수는 다음과 같습니다.","token: 대상의 token 정보","max: sda 최대 개수"]},{"l":"G. Token에서 dupicable SDA 설정하기","p":["Duplicable SDA를 사용하는 경우, 우선 multi sda 개수의 최댓값을 1로 설정해야 합니다.","update token sda max {token} {max} 명령어를 사용하여 토큰에 sda 개수의 최댓값을 설정합니다.","입력시 사용되는 매개변수는 다음과 같습니다.","token: 대상의 token 정보","max: sda 최대 개수","이후, update token duplicable {token} {value} 명령어를 사용하여 토큰에 dupicable SDA 사용 여부 및 중복하여 사용할 수 있는 sda의 개수를 선택 할 수 있습니다.","value: 복하여 사용할 수 있는 sda의 개수"]},{"i":"5-그룹group-관리하기","l":"5. 그룹(Group) 관리하기"},{"l":"Group 개념","p":["Moreh 솔루션을 이용하는 고객들에게는 사용자 자신을 식별하기 위해 암호화된 token을 받게 됩니다. 이 token은 “/etc/moreh/{토큰값}” 형식으로 가상 머신(VM) 내에 저장됩니다. 각 고객의 VM은 해당 토큰을 사용하여 마스터로 GPU 리소스를 요청하게 됩니다. Moreh Cloud Platform은 토큰을 기반으로 동작하는 클라우드 시스템이므로, 토큰이 없으면 GPU 연산 및 PyTorch 실행이 제한됩니다.","그룹 기능은 고객의 토큰에 따라 사용할 수 있는 AI 가속기 디바이스와 그 수를 제어하는 기능입니다. 예를 들어, A 고객은 Small과 Medium만 사용하도록 설정된 SDAModelGroupA에 연결됩니다. B 고객은 Medium부터 Large와 xLarge까지 옵션을 선택할 수 있도록 제한을 설정됩니다. 이렇게 그룹 기능을 통해 유연하게 GPU 자원을 조절할 수 있게 됩니다. KT Cloud 관리자분들께서는 Group기능으로 고객들의 GPU 자원 관리를 보다 원활하게 수행하실 수 있습니다.","예를들어 위와 같이 Group 관계가 형성된 경우 UserGroupA의 Token이 할당된 고객은 Small과 Medium 디바이스만을 사용 가능하며 Large와 xLarge는 사용이 불가능합니다.","마찬가지로 UserGroupB의 TokenB, TokenC, TokenD가 할당된 고객은 Medium, Large, xLarge만을 사용 가능하고 Small 디바이스는 사용이 불가능합니다."]},{"l":"Group 구성","p":["사용자의 Token, SDA Model, Backend가 각각 group으로 존재하며 Membership이 User Group과 SDAModel 간에 관계를 형성합니다."]},{"l":"A. User Group","p":["SDAManager에서의 사용자 token으로 이루어진 그룹","하나의 token이 여러 user group에 포함될 수 있습니다.","moreh_smclient 명령어 : 자세한 파라미터는 smclient에서 확인","사용 예시","새로운 그룹을 만들어서 해당 그룹에 토큰을 집어넣고 싶은 경우","group_B에 속한 토큰을 group_C로 옮기고 싶은 경우","또는 다음과 같은 방법으로도 사용 가능"]},{"l":"B. SDAModel Group","p":["SDAModel들로 이루어진 그룹입니다.","하나의 token이 여러 sda model group에 접근할 수 있습니다.","user group의 token들이 쓸 수 있는 sda model을 제한합니다.","하나의 backend group과 관계되어 해당 sda model group에 속해있는 sda model을 사용해 sda를 만들면 그 sda는 해당하는 backend group안의 backend들만 사용","moreh-switch-model로 봤을때 어떤 그룹에 해당하는 sda model인지 확인가능","moreh_smclient 명령어 : 자세한 파라미터는 smclient에서 확인"]},{"l":"C. Backend Group","p":["backend들로 이루어진 그룹입니다.","하나의 backend는 하나의 그룹에만 들어갈 수 있습니다.","기본 그룹[id : 0]이 있어서 처음에는 다 기본그룹에만 들어가 있습니다.","sda model group과 관계되며 sda 들이 쓸 수 있는 backend를 제한합니다","moreh_smclient 명령어 : 자세한 파라미터는 smclient에서 확인"]},{"l":"D. Relation","p":["user group부터 시작되는 모든 group들간의 전체적인 관계를 보여줍니다.","moreh_smclient 명령어 : 자세한 파라미터는 smclient에서 확인"]},{"i":"6-멤버쉽membership-관리하기","l":"6. 멤버쉽(Membership) 관리하기","p":["user group과 sdamodel group간의 관계를 형성합니다.","N:M관계이므로 어느 한쪽에 종속될 수 없습니다.","moreh_smclient 명령어 : 자세한 파라미터는 smclient에서 확인"]}],[{"l":"Troubleshooting","p":["\uD83D\uDCCC 이 문서는 HAC 서비스 관리자를 위한 오류 해결 방안을 제공합니다.** 이 페이지의 해결 가이드대로 진행했음에도 같은 문제가 발생하거나 현재 발생하는 에러코드 및 메시지를 이 페이지에서 찾지 못하실 경우에는 고객지원을 요청해 주시기 바랍니다.","GPU 디바이스 온도가 86~ 93°C인 경우 주의 단계 알림","GPU 디바이스 온도가 94~ 97°C인 경우 경고 단계 알림","GPU 디바이스 온도가 98~°C인 경우 조치 단계 알림","GPU 부족","GPU 부족 문제는 다른 작업이나 사용자가 GPU 자원을 과도하게 사용하고 있어서 여유 자원이 부족하거나 메모리 누수 및 냉각 시스템(환기 부족), GPU 드라이버나 관련 설정 문제등 복합적인 요소가 GPU 부족 및 GPU 온도 알림의 원인일 수 있습니다.","GPU 에러","GPU 온도","HAC 서버상의 자세한 원인을 해결하고 파악하기 위해서는 고객지원을 요청 주시기 바랍니다.","Q. smclient를 접속해서 token은 생성되었는데 Job 이 실행되지 않습니다.","Q. 사용자 계정 별로 최대 GPU 자원의 양(SDA 개수)을 제한하려면 어떻게 해야 하나요?","Q. 웹콘솔에서 GPU 부족 or GPU 온도알람이 뜨는데 정확한 원인을 파악하고 해결할 수 있는 방법은 무엇인가요?","User Management 페이지에서 Max SDA 수를 제한하고자 하는 해당 Token을 클릭한 후 사용가능한 최대 SDA 개수를 입력합니다.","물리 GPU에 에러가 발생한 경우","아래 알람 중 GPU 부족 알람이 뜨는 경우 해당 Job과 관련된 에러의 세부 로그를 확인하면 종종 문제의 근본 원인을 찾는 데 도움이 됩니다. Job & History 페이지에서 개별 작업 항목을 클릭하면 세부 로그 파일을 분석하여 문제 발생 시간, GPU 자원 사용에 관한 작업 및 오류 메시지를 확인할 수 있습니다.","클러스터에 배정된 GPU 자원이 부족하여 대기열 속 다음 작업을 진행하지 못하는 경우","현재 고객님의 VM의 token에 설정된 UserGroup이 꼬였을 가능성이 있습니다. show usergroup 과 show sdamodelgroup 명령어로 접근가능한 SDAModel들을 확인하세요."]}],[{"i":"hachyperscale-ai-computing-사용하기","l":"HAC(Hyperscale AI Computing) 사용하기"},{"l":"남청주 HAC 서버 접속하기","p":["관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","여기서는 아래 VM 접속정보를 제공하였다고 가정하겠습니다.","다음은 VM 접속정보를 활용하여 남청주 HAC VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"모델 학습 실행하기","p":["여기서는 Bert 모델을 학습해 보겠습니다. 먼저 Bert 모델을 다운로드합니다.","설치 완료 이후 학습하고자 하는 모델 폴더로 이동합니다.","python train.py 를 실행하여 Bert 모델의 사전 학습을 진행합니다.","모델 학습을 강제 중단 혹은 종료로 인해 Python 프로세스가 종료되지 않는 경우를 방지하기 위해, moreh-smi -r 명령어를 통해 학습 프로세스를 종료하시길 권장드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다.","moreh-smi 를 통해 실행 중인 학습 프로세스 및 GPU 자원 사용량을 확인할 수 있습니다."]}],[{"l":"Getting Started"},{"l":"HAC 서버 접속 및 사용하기 Quick start","p":["The following sample demonstrates a very basic sample.md page sample with a page title and one paragraph.","We can build on the above sample by adding more content and formatting, such as bold text, images, and lists.","At a very basic level, to create a new page for your Retype project, do the following:","Make a readme.md file","Add a # title","Start writing"]},{"l":"Home page","p":["Your project should include a default file ( index.md, default.md, readme.md, or welcome.md) within the root of the project. If there is a default file within the root folder, Retype will use that page as your home page. Clicking on the top-left logo or title will navigate to the home page.","Outside of the root of your project, adding a file with the exact same name as folder, will also act as a default page for that folder. For instance, adding /guides/guides.md is equivalent to /guides/index.md.","The default files can be used inside any folder of the project. Given the following folder and file structure, where Guides is a folder...","...Retype will create three pages in your website and the pages will be available at the following locations:","/","/guides/","/guides/getting-started/","If your home page is the Retype generated Welcome page, add a default page to the root of your project. The home page file can be named index.md, default.md, readme.md, or welcome.md."]},{"l":"Components","p":["In addition to the standard Markdown options, Retype includes many custom components so you can easily add extra \uD83D\uDC8E flair \uD83D\uDC8E to your document.","The most commonly used Retype components include Alert and Tab:"]},{"l":"Alert","p":["This is an Alert"]},{"l":"Tab","p":["This is Tab 1","This is another Tab","See all components"]},{"l":"Prerequisites","p":["Retype is installed using either npm, yarn, or the dotnet CLI.","You only need one of those three package managers as a prerequisite, although all three could be installed on your computer too. It's up to you. \uD83D\uDE4C","Package Manager","Supported Platforms","npm","yarn","dotnet"]},{"l":"Install","p":["It takes just a few seconds to install Retype using any of the following commands. Choose the command based on a package manager you have installed on your computer.","That's it! \uD83C\uDF89 Your new Retype website should be up and running. \uD83C\uDF89","If you already have the dotnet CLI installed on your machine, installing using dotnet tool install retypeapp --global will be the fastest option, but any of the options should install within seconds. They all produce the same result and run with the same performance. The dotnet package size is the smallest."]},{"l":"Update","p":["Update to the latest release of Retype using one of the following commands for the package manager that you initially installed Retype with. For instance, if you used npm to install Retype, run the npm update command to update Retype locally."]},{"l":"Uninstall","p":["Done with Retype? It's okay, we understand. \uD83D\uDE22","Uninstalling Retype is just as simple as installing. Use the same package manager to uninstall as you did to install. For instance, if you used npm to install Retype, run the npm uninstall command to remove.","All Retype related files and folders within your project can be deleted, such as the retype.yml file and the generated .retype folder."]},{"l":"Platform specific","p":["The default retypapp NPM package is a bundle of several platform specific packages. The installer will automatically detect and choose the correct platform package from the bundle during installation.","The bundle provides convenience although at the cost of an increased download size.","The dotnet package installer will automatically download the platform specific package.","For NPM and Yarn, it is possible to install smaller platform specific packages without the bundling. Currently, four separate platforms are supported and can be installed independently from the primary retypeapp package."]},{"l":"macOS","p":["OS","Version","Architectures","10.15+","x64, Arm64"]},{"l":"Windows","p":["OS","Version","Architectures","Windows 10 Client","Version 1607+","x64, x86, Arm64","Windows 11","Version 22000+","Windows Server","2012+","x64, x86","Windows Server Core","Nano Server","Version 1809+","x64"]},{"l":"Linux","p":["10+","12 SP2+","15+","18.04+","3.15+","36+","7","7+","8","Alpine Linux","Architectures","CentOS Linux","CentOS Stream Linux","Debian","Fedora","openSUSE","Oracle Linux","OS","Red Hat Enterprise Linux","SUSE Enterprise Linux (SLES)","Ubuntu","Version","x64","x64, Arm64","x64, Arm64, Arm32"]}],[{"l":"Docker 이미지로 Moreh 실행하기","p":["Docker 이미지로 Moreh 실행하기 ( moreh-docker-run)"]},{"l":"Hyperscale AI Computing 서비스에서 Docker로 Moreh 솔루션을 실행하는 방법","p":["Hyperscale AI Computing(이하 HAC) 서비스는 도커 컨테이너 안에서 AI 가속기를 사용하는 PyTorch 프로그램을 실행할 수 있도록 전용 도커 이미지를 제공하고 있습니다. VM에서 다음의 명령어들을 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다."]},{"l":"moreh-docker-run","p":["moreh-docker-run 명령어를 사용해 Moreh 솔루션이 담긴 도커 이미지를 실행합니다. 추가적으로 다른 옵션값을 안주고 실행했을 경우에는 현재까지 배포된 Moreh 솔루션 이미지 중 가장 최신 버전 도커 이미지를 실행하게 됩니다.","moreh-docker-run 명령어 뒤에 추가 옵션을 통해 도커 이미지만 다운로드 받기, 버전 확인 등을 실행할 수 있습니다.","moreh-docker-run 명령어는 Moreh 솔루션 23.11.0 버전 이후로는 기본적으로 pytorch 1.13.1 버전의 도커 이미지를 제공하고 있습니다. 23.11.0 버전 이전으로는 기본적으로 pytorch 1.7.1 버전의 도커 이미지를 제공하고 있습니다."]},{"l":"Supported Arguments","p":["pullonly (-p)","해당 옵션값을 추가로 줄경우, Moreh 솔루션 이미지를 바로 실행하지 않고 단순히 다운로드하게 됩니다.","해당 옵션값을 사용할 때는 --target 옵션값을 추가로 사용할 수 있으며, --target 옵션 값 뒤에는 아래 예시 명령어와 같이 버전을 명시해줘야 합니다. 만일 없을 경우 최신버전 이미지를 가져오게 됩니다.","version (-v)","Moreh 솔루션 도커 이미지 버전명을 보여줍니다.","—-target {VERSION}","특정 Moreh 솔루션 버전의 도커 이미지를 실행합니다. 기본값은 최신 모레 솔루션 버전이 들어가게 됩니다.","--torch {VERSION}","Moreh 솔루션 도커 이미지내에 설치된 torch 버전을 명시합니다. 기본값은 1.13.1입니다. ( Moreh솔루션 23.11.0 이후)","**--tensorflow {VERSION}**","Moreh 솔루션 도커 이미지 내에 설치된 Tensorflow 버전을 명시합니다. 기본값은 2.9.0입니다. 현재 Moreh 솔루션에서는 tensorflow 2.9.0 버전만 제공 중 인 점 참고부탁드립니다."]},{"l":"HAC 서비스에서 Docker로 Moreh 솔루션을 실행하는 시나리오","p":["VM에서 다음과 같이 실행하여 AI 가속기가 활성화된 컨테이너를 실행할 수 있습니다.","만일, 특정 버전의 Moreh 솔루션 이미지를 실행하고 싶다면, 위 명령어 뒤에 —-target 이라는 옵션을 추가하여 원하시는 Moreh 솔루션 버전 도커 이미지를 실행하실 수 있습니다. 만일 해당 옵션 없이 moreh-docker-run 을 실행하면 현재까지 배포된 Moreh 솔루션 중 최신 버전으로 이미지를 실행하게 됩니다.","컨테이너 안에서 AI 가속기 정보를 조회하고 PyTorch 프로그램을 실행시킬 수 있습니다.","컨테이너 안에서 인식되는 AI 가속기는 VM에 할당된 AI 가속기와 동일한 것입니다. VM에서 가속기 모델을 변경하면 컨테이너 안에서도 적용되며 그 반대도 마찬가지입니다. 또한 VM에서 AI 가속기를 사용하는 동안은 컨테이너 안에서는 AI 가속기를 사용할 수 없으며 이것 역시 반대도 마찬가지입니다. 예를 들어 VM에서 AI 가속기를 사용하는 pytorch-sample.py 프로그램이 실행 중인 동안 컨테이너에서 AI 가속기를 사용하는 다른 프로그램을 실행할 경우, 아래와 같은 메시지를 출력하고 VM에서 pytorch-sample.py 프로그램이 끝날 때까지 대기하게 됩니다.","이 문서의 나머지 부분에서는 HAC 서비스를 위한 Docker 컨테이너를 실행하는 과정을(즉, moreh-docker-run 명령이 내부적으로 하는 일을) 단계별로 자세히 설명합니다.","\uD83D\uDCA1 도커를 사용하지 않고도 VM 안에서 바로 AI 가속기를 사용해 PyTorch 프로그램 실행이 가능합니다. 이 문서는 특별히 도커 기반으로 실행해야 하는 애플리케이션이 있는 분들을 대상으로 합니다."]},{"l":"도커 이미지 내려받기","p":["위와 다르게, 단순히 Moreh 솔루션 이미지만 내려받고 싶으시다면 —-pullonly (-p) 옵션을 활용하여 이미지를 내려받을수 있습니다.","해당 명령어도 위와 동일하게 만일 특정 버전의 Moreh 솔루션 이미지를 내려받고싶다면, —-target 옵션 추가로 이를 수행하실수가 있습니다. 만일 해당 옵션없이 moreh-docker-run --pullonly 을 실행하면 현재까지 배포된 Moreh 솔루션중 최신 버전으로 이미지를 실행하게 됩니다."]},{"l":"Docker Container runtime으로 컨테이너 시작","p":["moreh-docker-run 외에 다음과 같이 docker run 명령으로 동일하게 컨테이너를 실행할 수 있습니다. 이 때 다음의 옵션을 포함시켜야 합니다.","v /etc/moreh:/etc/moreh"]}],[{"l":"GPU 자원 변경하기"},{"l":"moreh-switch-model","p":["VM에서 사용할 GPU의 개수를 조정할 수 있습니다. 다음 명령어(moreh-switch-model)를 통해 SDA를 변경할 수 있습니다.","현재 지원하는 SDA는 다음(Figure 1)과 같습니다. 번호로 SDA을 선택할수있고, q(또는 Q)로 대화를 종료 할 수 있습니다.","제일 작은 단위의 SDA는 Small.64GB이며 총 64GB 메모리를 가지고 있습니다. 그 이상 SDA는 Small.64GB의 배수만큼의 계산능력과 메모리를 가집니다. 예를 들어 Large.256GB는 Small.64GB에 비해 4배의 계산능력과 메모리를 가집니다."]}],[{"l":"K8S Cluster에서 Moreh 솔루션 사용하기"},{"l":"K8S Cluster에 접근하기 위한 서버 접속","p":["K8S Cluster를 사용하기 위해 moreh-k8s-master-vm01 서버로 접속해야합니다.","관리자가 이용자에게 제공한 VM 접속정보(IP, Port, SSH Key)를 입력해 접속할 수 있습니다.","관리자가 해당 VM 접속정보를 이용자에게 제공하였다고 가정해보겠습니다.","다음은 VM 접속정보를 활용하여 VM에 ssh 명령어로 접속하는 예시입니다."]},{"l":"Pod을 띄우기 위한 Manifest 파일 작성","p":["$ kubectl apply -f {파일 경로}","$ kubectl exec -it {pod 이름} -n {namespace} -c {container 이름} -- /bin/bash","$ kubectl get pods -n {metadata.namespace}","apply: 해당 액션으로 쿠버네티스 리소스를 생성/수정","f: 파일 경로","K8S 클러스터 안에서 pod을 띄우기 위해 다음과 같이 작성합니다.","K8S 클러스터에 pod을 생성하기 위해 다음의 명령어로 위에서 작성한 manifest 파일을 적용합니다.","K8S 클러스터에 해당 pod이 생성되었는지 다음의 명령어로 확인합니다.","Manifest 파일은 쿠버네티스 오브젝트를 관리하기 위한 선언적 specification을 포함하는 YAML 파일입니다.","metadata.name: pod의 이름","spec.template.spec.containers[0].env[0].value: 사용할 토큰","spec.template.spec.containers[0].image: Moreh 솔루션의 도커 이미지","spec.template.spec.containers[0].name: container의 이름","먼저 모레 솔루션이 작동하는지 여부를 moreh toolkit을 활용해 확인해봅니다.","사용자가 작성해야 할 주요 key는 다음과 같습니다.","생성한 pod에 다음의 명령어로 접속합니다."]},{"l":"Moreh Toolkit 사용","p":["moreh-smi","moreh-switch-model","만약 moreh tools를 실행했을 때 다음과 같이 ‘moreh::InvalidToken’ 에러가 발생한 경우 토큰 설정을 해주어야 합니다.","컨테이너 내부에서 /etc/moreh/token 에 할당받은 토큰을 입력하면 위의 문제가 해결됩니다."]},{"l":"Duplicable SDA 설정","p":["추론 시스템을 구축하는 경우, 하나의 SDA에서 여러 프로세스를 만들 필요가 있을 수 있습니다. 이러한 경우 duplicable SDA 설정을 통해 하나의 SDA에서 다수의 GPU 활용 프로그램을 실행할 수 있습니다.","Duplicable SDA는 moreh-smclient 를 통해 설정할 수 있습니다.","참고 링크 : moreh-docs"]},{"l":"PyTorch 학습","p":["샘플 코드인 pytorch-sample.py를 사용해 학습을 진행하면 다음과 같은 결과를 얻을 수 있습니다."]},{"l":"사용 완료한 Pod 제거","p":["pod을 제거하기 위해서는 먼저 deployment를 삭제해야합니다.","$ kubectl delete pod {pod 이름} -n {namespace} 로 pod을 삭제하면 deployment 컨트롤러가 새 pod을 생성하여 복제본 수를 유지하려고 하기 때문입니다.","다음의 명령어로 deployment를 삭제합니다.","$ kubectl delete deployment {deployment 이름} -n {namespace}","그 후 pod을 제거합니다.","$ kubectl delete pod {pod 이름} -n {namespace}","pod이 삭제되었는지 확인합니다.","$ kubectl get pods -n {namespace}"]}],[{"l":"Moreh 솔루션 업데이트 하기","p":["Moreh 솔루션은 주기적으로 업데이트되면서 솔루션의 전반적 성능이 개선되고 있습니다. Moreh 솔루션을 활용하는 방식에 따라 특정 버전의 Moreh 솔루션만을 사용하실 수 있지만, 가급적 최신 Moreh 솔루션을 사용하시는 것을 권장하고 있습니다. Moreh 솔루션을 업데이트하시면 사용하시는 환경의 Deep learning framework(PyTorch, TensorFlow) 및 Moreh driver 등의 필수 패키지들이 업데이트됩니다."]},{"l":"update-moreh","p":["Moreh 솔루션은 다음 명령어를 통해 업데이트하실 수 있습니다.","기본적으로 위 명령어 실행 시 현재까지 배포된 버전 중 최신 버전으로 업데이트를 진행합니다.","-target","Moreh 솔루션을 특정 버전으로 다운(업)그레이드를 할 수 있는 옵션입니다. --target 옵션 뒤에는 특정 버전을 아래와 같이 기입해주시면 됩니다."]},{"l":"Deep Learning Framework 버전 변경하기","p":["Moreh 솔루션은 Pytorch 1.7.1 버전뿐만이 아닌 Pytorch 1.10.0, 1.13.1 버전과 Tensorflow 2.9.0 버전에 대해서도 제공하고 있습니다.","다른 버전의 Framework 설치를 위한 옵션은 다음과 같습니다."]},{"l":"PyTorch 버전 변경하기"},{"l":"TensorFlow 버전 변경하기","p":["\uD83D\uDCA1 Tensorflow와 Pytorch 1.10.0 혹은 1.13.1 버전은 동시에 설치를 할 수 없습니다."]}],[{"l":"Reference Model 학습하기","p":["Reference Model (이하 RM) 이란?","Moreh framework 에서 학습, 추론이 가능한 딥러닝 모델을 의미합니다. 정기적으로 프레임워크와 함께 배포되며 Moreh 솔루션에서 딥러닝 학습에 필수적인 단계들을 수행할 수 있는 45종의 PyTorch 모델과 14종의 TensorFlow 모델을 다운로드할 수 있습니다. 따라서 사용자는 RM을 활용하여 직접 코딩하지 않아도 바로 학습, 추론을 수행할 수 있습니다.","Moreh 솔루션에서 지원하는 AI 프레임워크인 PyTorch와 TensorFlow, 그리고 학습 실행 방법을 설명 드리겠습니다."]},{"l":"PyTorch"},{"l":"1. RM 코드 다운로드","p":["아래 간단한 명령어 한 줄로 다양한 RM 코드를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 RM Code 설치 파일을 다운로드하고 실행하여 학습에 필요한 파일을 설치합니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다.","get-reference-model 명령어는 sudo 없이 사용하시길 권장드립니다. sudo 명령어가 포함될 경우, 실행 시 아래와 같은 에러가 발생할 수 있습니다."]},{"l":"2. RM 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"l":"3. 제공되는 모든 RM 목록 확인하기","p":["현재 어떤 모델 코드들이 제공되는지 궁금하시다면 —-show(또는 -s) 옵션을 이용하여 확인할 수 있습니다. 가장 범용적으로 쓰이는 딥러닝 모델과 Moreh 솔루션을 이용한 딥러닝 학습 모범 사례로 쓰일만한 안전한 모델들이 목록에 나타납니다."]},{"l":"4. RM 설치 파일 설정하기","p":["모델 설치 파일 (.sh) 에 대해서 수정 사항이 필요할 경우엔 아래와 같이 --download-only 옵션을 추가하여 모델 설치 파일만 다운로드 하실수도 있습니다. 해당 옵션을 추가하고 실행하면 실행 경로에 install_MODEL_NAME.sh 파일이 생성됩니다.","다음은 install_resnet.sh 파일을 다운받는 명령어 예시입니다.","모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","HAC VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 ResNet 모델을 설치하는 예시입니다.","—-download-only 옵션과 —-download-dir 옵션은 같이 사용하실 수 있습니다.","다음은 HOME경로에 있는 test 폴더에 instsall_resnet.sh 파일만 다운로드하는 명령어 예시입니다."]},{"l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]},{"l":"Tensorflow"},{"l":"1. TensorFlow 가상 환경","p":["처음 VM 생성 시 기본으로 tensorflow 이름의 Tensorflow용 conda 가상환경이 존재합니다. Tensorflow conda 환경이 없는 사용자 분들은 아래와 같은 방법으로 TensorFlow를 위한 가상환경을 생성하시기 바랍니다."]},{"l":"2. Tensorflow RM 코드 다운로드","p":["get-reference-model 명령어 한 줄로 다양한 Reference Model(이하 RM) Code를 얻게 됩니다.","위와 같은 명령어 실행 시 ResNet에 대한 RM Code 설치 파일 및 샘플 데이터을 다운로드하게 되며, 동시에 해당 설치 파일을 실행시켜 실행환경을 세팅해줍니다. 명령어 실행 완료 시 모델명에 따른 폴더가 생성이 되며 해당 폴더로 들어가 아래 명령어로 바로 모델을 실행(학습)시킬 수 있습니다."]},{"l":"3. RM 옵션 값 확인하기","p":["현재 get-reference-model 에서 지원하는 옵션 값들을 보고 싶으시다면, 아무런 옵션 값을 주지 않고 실행하거나, -h 옵션을 주면 보실 수 있습니다."]},{"i":"4-rm-설치-파일-설정하기-1","l":"4. RM 설치 파일 설정하기","p":["모델 설치 경로를 수정하고 싶으시다면 —-download-dir 옵션 값으로 모델 설치 경로를 수정하실 수 있습니다. 해당 옵션 값이 존재하지 않을 경우에는 기본 경로인 /home/ubuntu 에 설치가 됩니다.","HAC VM에서 /home의 기본 용량이 100GB이기 때문에 추가 디스크가 제공되는 경우가 있습니다. 위 설정을 통해 추가 디스크가 마운트된 디렉토리를 설정할 수 있습니다.","다음은 /data/tf-rm 경로에 ResNet 모델 파일을 다운받는 명령어 예시입니다."]},{"i":"5-모델-학습-시작하기-1","l":"5. 모델 학습 시작하기","p":["홈 디렉터리 아래의 해당 모델 디렉터리로 이동한 다음 train.py 스크립트를 실행하여 모델 학습을 시작할 수 있습니다."]},{"i":"hyperparameter-변경하기-1","l":"Hyperparameter 변경하기","p":["b 옵션은 mini-batch size, 즉 학습 이미지 몇 장을 한 번에 AI 가속기에서 학습시킬 것인지를 지정합니다. AI 가속기 사양이 높아질수록 거기에 맞춰 mini-batch size를 키워 주어야 최적의 성능을 얻을 수 있습니다. Hyperscale AI Computing의 AI 가속기 모델별로 권장하는 실행 옵션은 해당 모델 매뉴얼 을 참고하십시오."]}],[{"i":"gpu-자원-모니터링-moreh-smi","l":"GPU 자원 모니터링 (moreh-smi)","p":["$ MOREH_VISIBLE_DEVICE=0 python train_your_script_00.py$ MOREH_VISIBLE_DEVICE=1 python train_your_script_01.py","1~ 5번 명령어를 통해 단일 SDA 디바이스를 설정하고 모니터링 할 수 있으며, 6~8번 명령어를 통해 다중 SDA 디바이스를 설정할 수 있습니다.","AI 가속기 디바이스, 즉 Software-Defined Accelerator(이하 SDA)는 아래 8가지 명령어로 사용할 수 있습니다.","Device ID 0번 SDA → train_your_script_00.py 을 실행함과 동시에","Device ID 1번 SDA → train_your_script_01.py 을 실행할 수 있습니다.","HAC 서비스의 다중 SDA는 Token 1개당 1개 이상의 디바이스 종류를 생성/삭제할 수 있는 기능을 지원합니다. 하나 이상의 디바이스가 지원되는 것과 동시에 사용자 친화적으로 인터페이스가 구성되어 하나의 Token으로 여러 개의 디바이스의 프로세스를 유연하게 실행할 수 있습니다.","moreh-smi --reset- SDA 프로세스 종료하기","moreh-smi -i- SDA 활용 상태 모니터링하기","moreh-smi -p- SDA 상세 하드웨어 상태 모니터링하기","moreh-smi -t- SDA 토큰 정보 확인하기","moreh-smi device --add- SDA 생성하기","moreh-smi device --rm- SDA 삭제하기","moreh-smi device --switch- SDA 디바이스 기본값 변경하기","moreh-switch-model- SDA 변경하기","SDA 복제 기능( Duplicable) 설정을 통해 최대 횟수만큼 병렬 학습을 진행할 수 있으나 해당 기능은 관리자를 통해 설정 요청 부탁드립니다.","VM 1개를 여러 명이 동시에 공유해야 할 경우, VM의 자원을 효율적으로 활용할 수 있습니다.","각 명령어의 다양한 옵션에 대해서 더 자세히 알고 싶다면 moreh-smi --help 로 확인 가능합니다.","단일 SDA를 사용한다면 moreh-switch-model 명령어를 통해 하나의 GPU 자원의 종류를 선택할 수 있습니다. 반면에 다중 SDA를 사용한다면, 하나의 VM에서 여러 개의 SDA 디바이스를 동시에 선택하고 실행할 수 있습니다.","단일 SDA와 다중 SDA의 차이점","실행 프로세스","예를 들어 아래와 같이 moreh-smi device --add {model_id} 로 SDA를 추가하여 총 2개의 SDA가 설정되었다면 1개의 Token에 대해 VM 한 곳에서 동시에 2개의 프로세스를 실행할 수 있습니다.","위 명령어로 여러 개의 GPU 묶음을 할당하여 병렬 학습을 진행할 수 있습니다.","위와 같은 상황에서 병렬 실행을 통해 동시에 GPU 자원을 사용할 수 있습니다.","이제 개별 명령어에 대해 설명 드리겠습니다.","하나의 VM에서 여러 개의 SDA 디바이스를 동시에 실행함으로써 아래와 같은 다양한 장점을 얻을 수 있습니다.","학습에 사용할 하이퍼파라미터를 탐색하기 위한 Hyperparameter Tuning 작업을 여러 번의 학습을 동시에 실행하여 최적의 설정 값을 찾을 수 있습니다."]},{"l":"1. SDA 활용 상태 모니터링하기 moreh-smi","p":["Moreh 소프트웨어 툴은 moreh-smi 명령어를 통해 현재 선택된 SDA 모델, 실행 중인 학습 프로세스, GPU Resource를 얼마나 할당받고 있는지를 확인할 수 있습니다."]},{"i":"2-sda-token-정보-확인하기-moreh-smi--p","l":"2. SDA token 정보 확인하기 moreh-smi -p","p":["moreh-smi -p 명령어로 현재 선택된 SDA 모델에 할당된 노드의 아래와 같은 정보를 확인할 수 있습니다."]},{"i":"3-sda-token-정보-확인하기-moreh-smi---token","l":"3. SDA token 정보 확인하기 moreh-smi --token","p":["Token 값은 사용자를 식별하기 위한 해시 값이며 사용자마다 고유 값을 가지고 있습니다. Token은 일반적으로 사용자의 가상 머신(VM) 안에 위치하며, HAC 서버는 Token 값을 바탕으로 사용자를 식별하고 학습이 실행되므로, Token 없이는 GPU 연산 및 Python 애플리케이션을 실행할 수 없습니다.","moreh-smi --token 또는 moreh-smi -t 명령어로 VM에서 Token 설정 상태를 확인할 수 있습니다.","터미널에 해당 명령어를 입력하면 어떤 Token이 설정되어있는지 확인할 수 있습니다."]},{"l":"4. SDA 변경하기 moreh-switch-model","p":["moreh-switch-model 명령어를 통해 SDA 디바이스를 변경하여 가상 머신에서 사용할 GPU 리소스의 양을 조정할 수 있습니다.","moreh-switch-model 명령어를 사용하면 아래와 같은 입력창이 나타납니다.","1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “The KT AI Accelerator model is successfully switched to .” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA 모델로 변경됩니다. 여기서는 1번 Small.64GB 로 SDA 모델을 변경해보겠습니다.","변경을 계속하거나 q 또는 Q 를 통해 SDA 모델 변경을 종료할 수 있습니다."]},{"i":"5-sda-프로세스-종료하기-moreh-smi---reset","l":"5. SDA 프로세스 종료하기 moreh-smi --reset","p":["moreh-smi --reset 또는 moreh-smi -r 명령어를 통해 SDA 디바이스를 사용하고 있는 프로세스를 종료할 수 있습니다.","다음은 학습 중 종료한 예시입니다.","“Device release success.” 메시지와 함께 종료된 걸 확인할 수 있습니다.","아래와 같이 프로세스가 존재하지 않는 경우에는 “Device release failed. (Not running job.)” 메시지와 함께 실패합니다."]},{"i":"6-sda-추가하기-moreh-smi-device---add","l":"6. SDA 추가하기 moreh-smi device --add","p":["가상 머신(VM)이 생성된 직후에는 SDA는 1개까지만 기본값으로 제한되어 있습니다. 2개 이상의 SDA 사용이 필요한 경우 관리자에게 문의하여 제한값 설정을 요청 부탁드립니다.","하나의 VM 내에서는 최대 5개까지의 SDA를 생성할 수 있습니다.","Token의 제한 값이 변경된 이후 moreh-smi device --add 명령어로 SDA를 추가할 수 있습니다.","다음은 SDA를 추가하는 예제입니다.","moreh-smi device --add 커맨드를 입력하면 moreh-switch-model 과 동일한 인터페이스가 나타납니다. 1~ 13 중 사용할 모델에 해당하는 정수를 입력하면 “Create device success.” 메시지와 함께 입력된 디바이스 번호에 해당하는 SDA가 생성됩니다. 여기서는 3번 Large.256GB 로 SDA를 하나 더 생성해 보겠습니다.","moreh-smi device --add {model_id} 명령어를 통해 대화형 입력창 없이 바로 SDA를 생성할 수도 있습니다.","여기서 {model_id} 는 SDA 모델의 번호를 의미하며, Large.256GB 의 경우에는 ‘3’ 이 됩니다."]},{"i":"7-생성된-sda-디바이스-삭제하기-moreh-smi-device---rm","l":"7. 생성된 SDA 디바이스 삭제하기 moreh-smi device --rm","p":["생성된 SDA 디바이스를 삭제하려면 moreh-smi device --rm 명령어를 사용하면 됩니다.","moreh-smi device --rm {Device_ID} 명령어로 특정 Device_ID에 해당하는 SDA를 삭제해보겠습니다.","만약 help message에 device --add 와 같은 옵션의 도움말이 등장하지 않는다면 사용자 token에 대한 최대 디바이스 개수가 1로 설정된 것이므로 고객지원을 요청 부탁드립니다.","SSH 클라이언트와 통신이 끊겨 학습이 종료되는 문제를 방지하기 위하여, tmux 등의 터미널 다중화 프로그램을 이용하시는 것을 권장드립니다."]},{"l":"8. SDA 생성된 디바이스 기본값 변경하기","p":["moreh-smi device --switch {Device_ID} 명령어를 입력하면 이미 생성된 디바이스의 ID에 해당하는 디바이스로 변경됩니다.","moreh-smi device --switch {Device_ID} 를 통해 0번 Medium.128GB 을 기본 SDA로 변경해 보겠습니다.","생성된 SDA 모델 리스트 중 디바이스에 해당하는 정수를 입력하면 “Switch current device success.” 메시지와 함께 입력된 SDA가 기본 디바이스로 설정됩니다. 학습 프로세스 실행하면 설정한 기본 SDA 디바이스를 사용합니다.","여기서는 다시 1번 Medium.128GB 을 기본 SDA 디바이스로 변경해 보겠습니다.","이제 학습 실행 시 기본 값으로 1번 디바이스를 사용하게 됩니다."]}],[{"l":"Products","p":["Platform Cloud Service"]},{"i":"badge-hyper-ai-computing-service-hac-md","l":"[!badge Hyper AI Computing Service](hac.md)"},{"i":"badge-platform-cloud-service-platformcloudservice-md","l":"[!badge Platform Cloud Service](platformcloudservice.md)"},{"i":"badge-ai-model-hub-aimodelhub-md","l":"[!badge AI Model Hub](Aimodelhub.md)"},{"i":"badge-moreh-api-morehapi-md","l":"[!badge Moreh API](morehapi.md)"},{"i":"badge-hac-web-console-webconsole-md","l":"[!badge HAC Web Console](webconsole.md)"},{"l":"Variant"},{"i":"icon-rowstags-component","l":"icon: rows tags: [component]","p":["A Panel is created by surrounding a block of content with === and including a title for the Panel.","The title must be separated from the opening === by one space. The pattern === My Panel will work as expected, and ===My Panel will not.","Multiple Panels can be stacked by repeating Panel component configurations."]}],[{"l":"Getting Started"}],[{"l":"Overview"},{"l":"HAC Web Console 서비스 개요","p":["Admin User Manage","Cluster List","Global 모니터링","HAC Web Console Overview","HAC Web Console은 KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬에서 가장 적합한 사용자 경험을 제공합니다.","HAC Web Console을 사용하면 KTC 관리자는 다음과 같은 기능을 활용할 수 있습니다:","HAC 사용자 계정 관리","Home GPU 모니터링","Job & History","Notification Manage","SDA 모델 관리","Web Console Components","개발자의 니즈에 따라 GPU 자원 조정 가능: GPU 자원 분배에 관한 상태 값을 사용자의 편의와 요구에 따라 다양하게 조정할 수 있으며, 원활한 서비스 제공을 위해 필요한 조치를 즉시 취할 수 있습니다.","실시간 GPU 상태 모니터링: 서버 상태와 노드별 동작 여부를 확인하고, GPU의 가용성 및 예약 현황을 실시간으로 쉽게 파악할 수 있습니다. 또한, GPU 관련 작업 로그를 통해 성능 이슈나 문제를 신속하게 분석할 수 있습니다.","위 제공된 기능들을 통해 KT Cloud 관리자는 GPU 리소스를 효율적으로 관리하고, 클러스터의 안정성을 바탕으로 사용자들에게 원활한 서비스를 제공할 수 있습니다.","클러스터 설정"]}],[{"i":"#","p":["이 문서는 HAC Web Console로 GPU 자원 모니터링 및 관련 작업 등을 위한 가이드입니다. KTC 관리자가 HAC 클러스터의 자원 사용을 최적화하고 발생 가능한 문제를 빠르게 대응하는데 도움을 줍니다."]},{"l":"Web Console Components","p":["Cluster List","Admin User Manage","Notification Manage","Home GPU 모니터링","Global 모니터링","Job & History","HAC 사용자 계정 관리","SDA 모델 관리","클러스터 설정"]},{"l":"1. HAC Web Console 개요","p":["HAC Web Console은 KT Cloud 관리자를 위한 GPU 관리 도구로, GPU 리소스 상태를 실시간으로 모니터링하여 현재 할당된 AI 가속기의 작업 상태와 클러스터 내부의 문제를 빠르게 감지하고 관리할 수 있는 플랫폼입니다.","HAC Web Console을 사용하면 KTC 관리자는 다음과 같은 기능을 활용할 수 있습니다:","실시간 GPU 상태 모니터링: 서버 상태와 노드별 동작 여부를 확인하고, GPU의 가용성 및 예약 현황을 실시간으로 쉽게 파악할 수 있습니다. 또한, GPU 관련 작업 로그를 통해 성능 이슈나 문제를 신속하게 분석할 수 있습니다.","개발자의 니즈에 따라 GPU 자원 조정 가능: GPU 자원 분배에 관한 상태 값을 사용자의 편의와 요구에 따라 다양하게 조정할 수 있으며, 원활한 서비스 제공을 위해 필요한 조치를 즉시 취할 수 있습니다.","위 제공된 기능들을 통해 KT Cloud 관리자는 GPU 리소스를 효율적으로 관리하고, 클러스터의 안정성을 바탕으로 사용자들에게 원활한 서비스를 제공할 수 있습니다.","HAC Web Console은 여러 인터넷 브라우저를 지원하지만 크롬에서 가장 적합한 사용자 경험을 제공합니다."]},{"l":"2. Web Console Components","p":["Admin User Manage (관리자 정보 변경 및 권한 설정하기)","Cluster List","Global 모니터링","GPU 클러스터의 상태 및 실시간 사용 정보를 지표로 나타냅니다.","HAC GPU 사용을 위한 전용 관리 페이지입니다.","HAC 사용자 관리","Home GPU 모니터링","Job & History","Notification Manage (전체 알림 관리하기)","SDA 모델 관리","Web Console의 요소들과 각 기능을 어떻게 사용할 수 있는지 설명합니다.","각 클러스터 당 모레 솔루션의 버전을 관리할 수 있습니다.","각 클러스터에 포함된 모든 HAC 사용자 정보(사용자 그룹 수, 누적 사용량, 전체 SDA 개수 등)를 제공합니다.","각 클러스터에서 HAC 사용자에게 제공되는 SDA Model을 관리할 수 있습니다.","각각의 클러스터에 포함된 GPU 자원의 종합적인 모니터링이 가능하며 HAC 사용자에게 제공되는 GPU를 관리할 수 있습니다.","어떤 페이지에서든 빠르게 전체 GPU 클러스터에 포함된 GPU Node 들의 상태를 모니터링할 수 있습니다.","클러스터 내 GPU를 사용하는 작업을 관리하고 작업 진행 상황과 작업에 관련된 로그 및 세부사항을 확인할 수 있습니다.","클러스터 설정"]},{"l":"1. Cluster List","p":["✔️Master 권한의 관리자만 새로운 Admin 계정을 추가할 수 있습니다.","Admin User List 상단의 [+ Add] 버튼을 클릭하면 Modify Personal Info(Admin 개인 정보 수정) 모달과 동일한 모달이 아래와 같이 등장합니다. 모달에 추가할 관리자 정보를 입력합니다.","Admin User List에서 특정 관리자의 첫번째 Interaction 아이콘을 클릭하면 관리자에 대한 정보를 수정할 수 있습니다. Master 계정의 사용자는 계정(General, Master 모두)에 대한 정보를 수정 가능 하며, General 계정의 사용자는 개인 계정 정보만 수정 가능합니다.","Admin User Manage (관리자 개인 정보 변경 및 권한 설정하기)","Admin 관리자 계정 추가하기","Cluster List 는 HAC Web Console의 모든 클러스터에 대한 통합 개요 정보와 특정 클러스터의 세부 정보(패키지 배포 서버 상태, SDA Manager 상태, GPU의 클러스터 사용률 등)를 제공합니다.","Cluster 이름, IP 주소는 필수 입력 항목입니다.","Cluster 추가하기","General 계정 : 개인 계정 정보만 수정 가능","GPU 디바이스 온도가 86~ 93°C인 경우 주의 단계 알림","GPU 디바이스 온도가 94~ 97°C인 경우 경고 단계 알림","GPU 디바이스 온도가 98~°C인 경우 조치 단계 알림","GPU 부족","GPU 에러","GPU 온도","Master 계정 : Moreh에서 직접 만들어서 제공하는 계정이며 General, Master 계정 모두 생성과 수정 가능","Master 권한, General 중 선택합니다.","Notification Manage (전체 알림 관리하기)","Notification Manage 페이지의 Notification List(클러스터 알람 목록)에 [+ Add Filter] 버튼을 클릭하면 다음 필터 패널이 나타납니다. 알림 특정 태그를 추가/제외 가능합니다.","Untitled","개별 클러스터 삭제 시 확인 모달에서 [삭제] 버튼 클릭","관리자 ID","관리자 권한","관리자 이름 (필수 입력 사항)","권장사이즈: 120px(width) * 120px(height) 또는 1:1 비율","두번째 Interaction 아이콘을 클릭하면 해당 관리자의 권한을 General/Master로 변경할 수 있습니다. ✔️Master 권한의 관리자만 변경 가능합니다.","로그인 인증 정보로 로그인하여 HAC 웹콘솔에 접속하면 첫 페이지가 다음과 같이 표시됩니다.","메일 주소이며 한 번 생성된 후에는 변경 불가능합니다.","모니터링할 특정 기간에 대해 년, 월, 일 시간으로 시작 날짜와 종료 날짜를 입력합니다.","물리 GPU에 에러가 발생한 경우","비밀번호 (필수 입력 사항)","사용자 관리 페이지에서 왼쪽 사이드바의 [Permission Manage]를 클릭하면 아래와 같이 Admin User List가 나타납니다. Admin User List에는 사용자 프로필 아이콘, 관리자 ID, 관리자 이름, 권한 Type 정보와 Master 권한의 관리자가 상호작용가능한 아이콘이 제공됩니다.","상단 우측의 [Notification Manage] 버튼 과 [Admin User Manage] 버튼 을 클릭한 후 각 알람 관리 페이지와 Admin 사용자 관리 페이지로 이동하여 Admin 사용자 개인정보와 권한 및 웹콘솔의 모든 알림과 Admin 사용자를 관리할 수 있습니다.","선택 사항이며 미입력시 디폴트 아이콘이 제공됩니다.","세번째 휴지통 모양의 Interaction 아이콘을 클릭하면 해당 관리자를 삭제할 수 있습니다. ✔️Master 권한의 관리자만 삭제 가능합니다.","아래 모달 창이 뜨면 추가할 클러스터 정보(이름, IP 주소, Description)를 입력합니다.","아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","알림리스트 중 모니터링할 클러스터를 선택 가능합니다.","영문, 숫자 또는 대문자 포함 제한이 없습니다.","웹 콘솔의 첫 화면에서 아래 클러스터 추가 [+ ADD Cluster] 아이콘을 클릭합니다.","이 페이지에서 클러스터의 개요 정보를 확인하고, 클러스터 목록을 통해 개별 클러스터로 진입할 수 있습니다. 또한 관리자 계정의 개인정보와 권한을 설정할 수 있습니다.","작업 에러","제공되는 알림 분류 중 선택 가능합니다.","진행 중이던 작업이 에러가 발생하여 멈춘 경우","클러스터에 배정된 GPU 자원이 부족하여 대기열 속 다음 작업을 진행하지 못하는 경우","프로필 사진"]},{"l":"2. Home GPU Monitoring","p":["(예시) Group A 클러스터에 등록된 A100, V100, MI250 세 종류가 있을 경우 GPU 디바이스 종류의 개수: 3개 로 표현","00~05 로 그룹핑되어있는 부분이 같은 사용자가 사용하는 노드입니다. 그룹핑된 부분에 마우스 오버시 해당 디바이스 묶음을 사용하는 토큰에 대한 정보가 툴팁으로 제공됩니다.","00번 부터 07번까지 각 GPU 디바이스로 구분","Add Filter를 적용할 경우 선택된 필터링 내용을 해시태그 형태로 제공합니다.","CPU 온도와 노드 메모리 사용률 정보","Description (Cluster 추가 시 Admin 관리자가 입력한 노드 사용 관련 내용 )","GPU 디바이스 종류의 개수","GPU 디바이스의 사용 현황이 색상으로 표현됨","GPU 메모리 정보","GPU 정보","GPU 종류","GPU 현재 상태를 다음 3가지로 구분하여 선택된 상태에 해당하는 노드가 필터링 결과로 제공됩니다.","Grid(바둑판 뷰)의 노드 1개의 이미지","HAC Web Console 효율성 (Service Efficiency)","Node - Grid 에서 노드 1개의 정보는 아래와 같이 나타납니다.","Node Group","Node Group List 우측 상단에 [+ Add] 버튼을 클릭한 후 아래 모달에서 필요한 정보를 입력합니다.","Node Group 이름","Node Group은 다음 정보를 제공합니다.","Node List 에서 모니터링 리스트에서 제공하는 노드 정보는 위 Node - Grid(바둑판 뷰)의 셀과 동일합니다.","Node Monitor","Node 개수와 GPU 자원의 양으로 나타냄","Overview 클러스터 개요","Screen Shot 2023-07-30 at 4.19.00 PM.png","SDA Manager 상태 (원활/불량)","Untitled","User","그룹에 대한 설명","노드 그룹","노드 그룹 이름 (필수 입력 사항)","노드 그룹 추가하기","노드 목록에 필터링 적용하기","노드 이름 (호스트 이름)","노드가 소속된 GPU 디바이스 그룹","대기중 (Idle)","리스트 우측 상단에 다음 [+ Add Filter] 버튼을 클릭하여 아래 모달에 노드 목록에 표시될 항목을 선택합니다.","링크 클릭시 HAC 사용자 관리 페이지로 이동합니다.","모니터링 리스트는 Grid(바둑판 뷰)와 List(목록형 뷰)로 제공되며 사용중인 노드와 이름 순서로 정렬됩니다.","빨간색 - 사용 불가 (Shutdown)","사용 가능한 노드 개수","사용 불가 (Shutdown)","사용중 (Processing)","사용중인 Node 개수와 GPU 자원의 양을 전체 대비 백분율로 나타냄","삭제","상호작용","선택된 노드리스트","설명","수정","연관된 SDA 모델 그룹","전일 기준으로 1주일 동안 평균 사용한 노드 수와 GPU 디바이스 수 (전체 대비 백분율)","전체 노드 그룹, Group A, Group B, Group C에 해당하는 노드가 필터링 결과로 제공됩니다.","전체 노드 중 사용 불가능한 노드와 GPU 자원의 양을 전체 대비 백분율로 나타냄","전체 사용자 계정이 선택한 SDA Model의 GPU 자원의 총합 / 평균 사용중인 GPU 자원의 양 = %","전체 사용자 계정이 제공되며 특정 계정을 추가하거나 제외할 수 있습니다.","초록 - 사용중 (Processing)","최상단 디바이스 번호에 토큰 포함관계가 표현","클러스터에 포함된 전체 노드 리스트와 선택된 노드 리스트가 제공되며 검색, 체크박스 선택 등을 통해서 상호작용이 가능합니다.","특정 노드 이름 혹은 그룹이름에 대해 검색창에 찾아볼 수 있습니다.","패키지 배포 서버 상태 (원활/불량)","평균 사용 중인 노드 수","포함된 노드 개수","포함된 디바이스 종류","해당 디바이스 메모리의 현재 온도와 사용률을 나타냄","해당 클러스터를 사용중인 HAC 사용자 계정 개수","해당 클러스터에 포함되어 있는 전체 노드 수","현재 클러스터에서 사용 불가능한 노드 수","현재 클러스터에서 사용 중인 노드 수","현재 해당 클러스터에 등록된 물리적인 GPU 제품 종류의 개수","현재 해당 클러스터에 존재하는 사용자가 설정한 GPU 종류에 따라 필터링 가능하며 체크 박스 형태로 여러개 선택 가능합니다.","호함된 노드 수","회색 - 대기중 (Idle)"]},{"l":"3. Global 모니터링","p":["Global Monitoring 페이지는 사용자가 HAC Web Console 내부에서 전체 클러스터를 빠르게 시각적으로 모니터링할 수 있도록 도와주는 패널입니다. 로컬 화면의 좌측 Navigation 바 하단에 위치한 글로벌 모니터링 아이콘을 클릭하면 다음 페이지가 나타납니다.","Global Monitoring 페이지의 전체 클러스터 개요와 각 클러스터는 다음과 같은 정보를 포함합니다.","Overview - All Clusters (클러스터 개별 개요)","SDA Manager서버","Untitled","노드들 중 간혹 두 명 이상의 HAC 사용자가 하나의 노드를 나누어서 사용하는 경우가 있습니다.","따라서 하나의 노드를 두 명 이상의 HAC 사용자가 사용하는 경우에는 해당 노드에 마우스 오버 시 아래 툴팁 이미지와 같이 사용중인 노드 이름과 현재 상태(Processing/Idle/Shutdown), 사용시간, GPU index 번호, 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 나타납니다.","빨강 Shutdown - 해당 노드를 사용했던 사용자 계정 정보와 셧다운된 시각","사용 가능한 노드 수","사용 불가능한 노드 수","사용중인 노드 수","서비스 효율성","이런 경우 노드에 마우스 오버 시 나오는 정보 툴팁도 해당 노드를 사용하는 HAC 사용자가 한명일 때와 여러 명일 때가 구분됩니다. 예를 들어 3개의 노드와 4개의 GPU를 사용하는 경우 해당 HAC 사용자가 사용하는 3개의 노드에 마우스 오버하면 한 명의 유저에 대한 툴팁만 나오겠지만, 4번째 노드인 GPU 4개를 사용하는 노드에 마우스를 오버하면 해당 노드를 나누어서 사용하는 모든 엔드 유저에 대한 정보가 툴팁에 제공됩니다. 또한 툴팁에 제공되는 모든 엔드유저가 사용 중인 노드 시각화 또한 하이라이트 됩니다.","전체 노드 수","초록 Processing - 해당 노드를 사용하는 사용자 계정 정보와 사용시간","클러스터 모니터링","클러스터의 각 노드에 마우스 오버시 현상태에 따라 아래 정보가 제공됩니다.","패키지 배포 서버","평균 사용 노드 수","하나의 노드를 여러명의 HAC 사용자 사용했을때 툴팁","하나의 노드를 한명의 HAC 사용자 사용했을때 툴팁","회색 Idle - 해당 노드가 포함된 GPU 그룹 정보"]},{"i":"4-job--history","l":"4. Job & History","p":["Framework (사용 프레임워크 버전)","GPUs (SDA Model 이 사용중인 GPU 개수)","History List (작업 히스토리)","History List에는 가장 최근에 종료된 작업순으로 정렬됩니다.","Id (아이디)","Interaction (상호작용 아이콘 - 우선순위 변경하기, 특정 작업 취소하기)","Job List (작업목록)","Job Priority (작업 우선순위)","Job 목록에 사용자가 요청한 작업은 사용자의 우선순위에 해당되는 기본값을 가지고 들어오며, 만약 작업이 대기열에 들어가게 되면 해당 우선순위 값을 첫 번째 정렬 값으로 사용하여 대기열에 적용됩니다. 이렇게 정렬된 대기열(Queue)에 있는 각 작업의 우선순위를 수동으로 변경할 수 있습니다.","MAF ver (모레 솔루션 버전)","Overview (작업 개요)","Queued-> 클러스터에 해당 작업에 필요한 GPU가 부족하여 진행중이지 못한 작업","Request Time (작업 요청된 시간)","Running -> 현재 진행중인 작업으로 GPU 사용중","Running Time (진행 시간)","Start Time (시작 시간)","Status (현재 상태)","Untitled","Untitled-8.png","User (사용자)","Waiting Time (대기중인 시간)","개별 Job 항목을 클릭하면 확인할 수 있는 작업 로그","개별 클러스터에서 GPU를 사용하여 해당 클러스터에서 진행중인 작업(Job)과 작업 히스토리를 확인하고 GPU 배정이 필요한 작업 간의 우선 순위를 조정하여 먼저 할당 받을 수 있는 페이지입니다. 작업 목록에서 개별 작업 항목을 클릭하면 세부 로그를 확인할 수 있는 페이지로 이동합니다.","리스트에서 각 작업의 우선순위 변경 아이콘을 클릭하면 모달을 통해 작업 우선순위 변경이 가능합니다.","사용자 Job 대기열 우선순위 설정하기","사용자 계정 별로 기본 우선순위가 있으며 Queue에서 우선순위가 가장 높은 Job이 먼저 GPU 노드를 할당 받을 수 있습니다.","시,분, 일 변화 단위로 따라가기 (사용한지 25시간 -> 1D 1H 로 표기)","우선순위 값(-99~ 99 사이의 정수)이 99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당 됩니다.","작업 목록에는 다음 정보가 표시됩니다.","작업 우선순위(Priority)","작업 우선순위는 Job Queue에서 대기중인 Job중에서 할당받는 순서를 결정합니다.","전체 노드 혹은 노드 별로 확인이 가능합니다.","전체적으로 작업 목록(Job List)와 동일한 값을 제공하며 상태값(Status)만 Completed(완료), Expired(HAC사용자 또는 Admin의 input 없이 모종의 에러로 종료), Canceled(HAC 사용자가 수동으로 종료) 로 제공됩니다.","해당 작업이 가지는 고유 ID 정보","현재 사용 가능한 디바이스와 에러가 발생한 작업수 등을 표시됩니다."]},{"i":"5-end-userhac-사용자-관리하기","l":"5. End User(HAC 사용자) 관리하기","p":["-99~ 99 사이의 숫자로 설정","-99~ 99사이의 숫자 (default=0)","(default = not selected)","99로 갈수록 우선순위가 높으며 먼저 GPU 노드가 할당됩니다.","Admin 사용자가 지정한 HAC 사용자 그룹","default value = 0","default value = 1","GPU 사용 안하는중","GPU 사용중","GPU 작업 대기중","HAC 사용자 SDA 번호","HAC 사용자 정보 삭제하기","HAC 사용자 추가하기","HAC 사용자에게 제공되는 SDA의 고유 ID","HAC 사용자에게 허용되는 SDA 개수","Key-Value 쌍으로 입력합니다.","Max Multi Use: 1개의 SDA로 n 번 GPU를 할당할 때 n 의 최대값","MAX SDA","Max SDA = 1 인 경우 Max Multi Use 활성화","Max SDA = 1 인 경우에만 사용 가능합니다.","Max SDA 1 인 경우 Max Multi Use 비활성화","MAX SDA 수","Max SDA 수 (필수 입력사항)","Overview (전체 유저 개요 정보)","SDA Model * N","SDA 추가하기","Untitled","User List (사용중 - 대기중 순서로 정렬)","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 정보를 수정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 다음 정보를 입력합니다.","User List 에서 특정 HAC 사용자에 해당하는 첫번째 Interaction 아이콘을 클릭하면 사용자 환경변수를 설정할 수 있습니다. 아래와 같은 **** 모달이 뜨면 Key 와 Value 값을 입력합니다.","User List에 새로운 HAC 사용자를 추가하려면 우측 상단에 **[+ Add User]** 버튼을 클릭 후 아래 모달에서 다음 정보를 입력합니다.","User Manage 페이지에서는 사용자 관리 페이지에서는 해당 클러스터에 포함된 모든 HAC 사용자를 관리할 수 있습니다. 상단에 있는 전체 유저 개요 정보와 하단의 User List(사용자 목록)이 제공됩니다.","User Name","값이 1이 아닌경우 해당 MAX SDA 값만 제공됩니다.","값이 1인 경우 허용된 Multi Use 값이 제공됩니다.","누적 사용량 (Total Usage)","사용자 계정 정보 변경하기","사용자 그룹 설정하기","사용자 그룹 수","사용자 삭제","사용자 우선순위","사용자 이름 (User)","사용자 이름 (필수 입력 사항)","사용자 정보 변경시 아래 정보를 입력합니다.","사용자 정보 편집","사용자 환경변수 설정","사용자 환경변수 설정하기","사용자가 작업을 시작하면 해당 작업에 우선순위가 부여되며, 이 우선순위는 작업 목록에서 사용자 우선순위와 별개로 조정할 수 있습니다. (기본 값 = 0)","사용중인 SDA Model","상호작용 아이콘","소속 그룹 (User Group)","여러 Key-Value 쌍을 추가할 수 있으며 한 번 입력한 환경변수를 삭제할 수 있습니다.","우선 순위 (Priority)","작업 우선순위는 기본 값(0)과 작업 목록에서 조정 가능한 값으로 구분됩니다.","전체 SDA 수","전체 유저 수","좌측 휴지통 모양 아이콘을 클릭해서 사용자 정보를 삭제할 수 있으며 삭제 후에는 기본 정보를 불러올 수 없습니다.","총 누적 사용량 (GPU를 사용한 시간)","최근 실행 시간 (Recent Use)","하단의 SDA Model 선택은 한 개만 가능하고 추가 버튼 비활성화","하단의 드롭다운 버튼을 클릭해서 max SDA에서 설정한 N개의 SDA Model 추가 가능","현재 상태"]}],[{"i":"hachyperscale-ai-computing","l":"HAC(Hyperscale AI Computing)"},{"i":"목적용도","l":"목적/용도","p":["KT Hyperscale AI Computing 서비스는 인공지능 학습/추론을 위한 유연하고 확장성 높은 AI 가속기(accelerator)를 제공하는 서비스입니다. AI 가속기 위에서 PyTorch / Tensorflow 기반 딥 러닝 프로그램을 고성능으로 실행할 수 있습니다.","Hyperscale AI Computing 서비스는 가속기의 연산 성능과 메모리 용량을 가변적으로 조정할 수 있으며, 특히 기존 GPU Server로는 불가능했던 수준의 고사양을 선택할 수 있어 AI 모델 대형화에 탄력적으로 대응 가능합니다.","또한 AI 가속기는 실제 연산이 실행 중인 동안에만 동적으로 자원을 할당 받기 때문에 기존 pass-through 방식 GPU Server에 비해 합리적인 비용으로 서비스를 이용할 수 있습니다.","일반적으로 널리 사용되는 여러 가지 인공신경망 모델을 Hyperscale AI Computing 서비스 상에서 실행할 수 있도록, 공식 지원 모델에 대한 학습/추론 스크립트와 샘플 데이터가 함께 제공됩니다."]},{"i":"구조원리","l":"구조/원리","p":["KT Hyperscale AI Computing 서비스가 제공하는 AI 가속기는 PyTorch 및 TensorFlow에서 각각 'cuda:0', ‘/gpu:0’ 디바이스로 인식되며, 기존 CUDA 디바이스와 호환되는 API를 제공합니다. 따라서 기존에 NVIDIA GPU를 사용하던 방식 그대로 PyTorch , TensorFlow 프로그램을 작성, 실행할 수 있습니다.","AI 가속기에서 프로그램을 실행하면 별도의 resource farm에 위치하는 GPU 자원들이 VM에 동적으로 할당됩니다. 또한 프로그램이 종료되면 GPU 자원이 자동으로 할당 해제됩니다. 사용자가 실제로 GPU 자원을 실제로 점유한 양과 시간이 별도로 기록되어, 이에 비례한 요금이 부과됩니다.","기존 GPU Server에서는 연산 성능을 높이려면 GPU 개수를 늘리고 이에 맞게 DistributedDataParallel, MirroredStrategy 등을 사용하여 프로그램을 수정해야 했습니다.","반면 Hyperscale AI Computing에서는 단순히 AI 가속기를 더 고사양으로 변경한 다음, 단일 GPU를 위한 병렬화되지 않은 PyTorch/TensorFlow 프로그램을 실행하면 됩니다.","Hyperscale AI Computing 컴파일러가 자동으로 연산 작업을 병렬화하여 여러 GPU 자원에서 분산 처리하기 때문입니다. AI 가속기는 사양에 따라 수~ 수십 개의 GPU를 할당받아 사용할 것이나, 사용자는 GPU의 개수나 물리적 위치를 전혀 신경 쓰지 않아도 됩니다.","GPU 자원의 할당 및 사용은 애플리케이션 수준의 연산 오프로딩 기술로 구현되어 있어 기존 vGPU 가상화 기술에 비해 뛰어난 성능을 제공합니다."]}],[{"l":"Getting Started"},{"l":"HAC 서버 접속 및 사용하기 Quick start","p":["The following sample demonstrates a very basic sample.md page sample with a page title and one paragraph.","We can build on the above sample by adding more content and formatting, such as bold text, images, and lists.","At a very basic level, to create a new page for your Retype project, do the following:","Make a readme.md file","Add a # title","Start writing"]},{"l":"Home page","p":["Your project should include a default file ( index.md, default.md, readme.md, or welcome.md) within the root of the project. If there is a default file within the root folder, Retype will use that page as your home page. Clicking on the top-left logo or title will navigate to the home page.","Outside of the root of your project, adding a file with the exact same name as folder, will also act as a default page for that folder. For instance, adding /guides/guides.md is equivalent to /guides/index.md.","The default files can be used inside any folder of the project. Given the following folder and file structure, where Guides is a folder...","...Retype will create three pages in your website and the pages will be available at the following locations:","/","/guides/","/guides/getting-started/","If your home page is the Retype generated Welcome page, add a default page to the root of your project. The home page file can be named index.md, default.md, readme.md, or welcome.md."]},{"l":"Components","p":["In addition to the standard Markdown options, Retype includes many custom components so you can easily add extra \uD83D\uDC8E flair \uD83D\uDC8E to your document.","The most commonly used Retype components include Alert and Tab:"]},{"l":"Alert","p":["This is an Alert"]},{"l":"Tab","p":["This is Tab 1","This is another Tab","See all components"]},{"l":"Prerequisites","p":["Retype is installed using either npm, yarn, or the dotnet CLI.","You only need one of those three package managers as a prerequisite, although all three could be installed on your computer too. It's up to you. \uD83D\uDE4C","Package Manager","Supported Platforms","npm","yarn","dotnet"]},{"l":"Install","p":["It takes just a few seconds to install Retype using any of the following commands. Choose the command based on a package manager you have installed on your computer.","That's it! \uD83C\uDF89 Your new Retype website should be up and running. \uD83C\uDF89","If you already have the dotnet CLI installed on your machine, installing using dotnet tool install retypeapp --global will be the fastest option, but any of the options should install within seconds. They all produce the same result and run with the same performance. The dotnet package size is the smallest."]},{"l":"Update","p":["Update to the latest release of Retype using one of the following commands for the package manager that you initially installed Retype with. For instance, if you used npm to install Retype, run the npm update command to update Retype locally."]},{"l":"Uninstall","p":["Done with Retype? It's okay, we understand. \uD83D\uDE22","Uninstalling Retype is just as simple as installing. Use the same package manager to uninstall as you did to install. For instance, if you used npm to install Retype, run the npm uninstall command to remove.","All Retype related files and folders within your project can be deleted, such as the retype.yml file and the generated .retype folder."]},{"l":"Platform specific","p":["The default retypapp NPM package is a bundle of several platform specific packages. The installer will automatically detect and choose the correct platform package from the bundle during installation.","The bundle provides convenience although at the cost of an increased download size.","The dotnet package installer will automatically download the platform specific package.","For NPM and Yarn, it is possible to install smaller platform specific packages without the bundling. Currently, four separate platforms are supported and can be installed independently from the primary retypeapp package."]},{"l":"macOS","p":["OS","Version","Architectures","10.15+","x64, Arm64"]},{"l":"Windows","p":["OS","Version","Architectures","Windows 10 Client","Version 1607+","x64, x86, Arm64","Windows 11","Version 22000+","Windows Server","2012+","x64, x86","Windows Server Core","Nano Server","Version 1809+","x64"]},{"l":"Linux","p":["10+","12 SP2+","15+","18.04+","3.15+","36+","7","7+","8","Alpine Linux","Architectures","CentOS Linux","CentOS Stream Linux","Debian","Fedora","openSUSE","Oracle Linux","OS","Red Hat Enterprise Linux","SUSE Enterprise Linux (SLES)","Ubuntu","Version","x64","x64, Arm64","x64, Arm64, Arm32"]}],[{"l":"Moreh AI Model Hub","p":["Chatbot Comparison: 동일한 모델에 대한 파라미터 별 학습 시간 및 생성된 답변의 질을 비교하여 각 모델의 성능 차이를 비교할 수 있습니다.","Chatbot_Small, Chatbot_Medium, Chatbot_Large: 챗봇의 명칭은 사용된 언어 모델의 크기에 따라 구분되었습니다. 3개의 챗봇 모두 대형 언어 데이터를 기반으로 문맥을 이해하고 문장을 생성하며 다양한 주제에 대한 정보 제공, 질문 응답, 일상 대화를 통해 사용자와 상호작용합니다.","Code Generator: 사용자가 지정한 규칙 및 요구 사항에 따라, 프로그래밍 코드를 자동으로 생성하여 제공합니다.","Compare Model","Debugging: 입력한 함수를 디버깅 가능한 test case를 작성합니다.","Explain code: 사용자가 입력한 코드가 어떻게 작동하는지 설명합니다.","Generate code: 사용자가 작성한 주석을 수행하는 코드 작성합니다.","Image Generate AI","MAMH 의 목표는 AMD GPU만으로도 학습이 가능한 AI 모델을 사용하고 공유하는 과정을 단순화하고 개선하는 것입니다. 이 서비스는 다음 목적을 충족하기 위해 탄생하였습니다:","Moreh AI Model Hub 는 대규모 모델을 종합적으로 제공하는 서비스로, 언어뿐만 아니라 이미지 생성 및 모델 비교와 같은 다양한 작업을 수행합니다.","Moreh AI Model Hub(MAMH) 작동 방식","Moreh AI Model Hub(MAMH)는 무엇인가요?","Moreh AI Model Hub는 텍스트 및 이미지를 생성하고 언어를 번역하며 다양한 종류의 창의적인 콘텐츠를 작성하는 등의 작업을 하는 도구입니다.","Multi Modal AI","Random Image: 무작위로 선택된 이미지를 제공하는데, 일반적으로 사용자의 요청에 따라 랜덤하게 이미지를 생성합니다.","Text Generate AI","Text to Image Editing: 사용자가 입력한 텍스트 설명에 따라 이미지를 편집합니다.","Text to Image: 텍스트 입력을 기반으로 시각적 콘텐츠를 생성합니다.","Visual Question Answering: 이미지와 관련된 질문에 대답하는 기능을 제공합니다. 사용자가 이미지에 대한 질문을 하면, VQA는 이미지를 분석하고 자연어 처리 기술을 활용하여 해당 질문에 대한 응답을 생성하여 제공합니다.","공동 작업 및 공유: 모델 허브는 사용자 간에 AI 모델을 공동으로 작업하고 공유하는 데 편리한 방법을 제공합니다. 모델을 만들고 수정한 후 다른 사용자와 공유하거나 공동 작업할 수 있습니다. (To Be Determined)","모델 검색 및 선택의 용이성: Model Hub는 하드웨어 자원 및 시간 대비 학습 성능이 좋은 대규모 생성형 AI 모델을 검색하고 선택하는 과정을 단순화합니다. 사용자는 원하는 기능 및 작업에 적합한 모델을 쉽게 찾을 수 있습니다."]}],[{"l":"AI Model Hub FAQ"},{"l":"4. FAQ","p":["Q. Moreh Hub는 내 개인 데이터를 어떻게 사용하나요?","Moreh Hub가 제공하는 대형 AI 모델은 공개적으로 사용 가능한 콘텐츠, 라이센스가 있는 콘텐츠, 검토자가 생성한 콘텐츠를 포함하는 광범위한 텍스트 및 이미지를 학습합니다. Moreh는 서비스 판매, 광고 또는 사람들의 프로필 등을 생성하기 위해 데이터를 사용하지 않습니다. Moreh Hub가 제공하는 모델의 답변의 질을 높이고 사람들에게 더 유용하게 만들기 위해서만 채팅 데이터를 사용합니다.","Q. Moreh Hub로 만들어진 이미지나 텍스트를 팔 수 있나요?","콘텐츠 사용 약관 과 개인정보 보유 및 이용기간 에 따라 Moreh Hub로 생성된 이미지는 사용자에게 해당 이미지를 재인쇄, 판매 및 상품화할 권리가 있습니다.","Q. Moreh Hub는 몇개의 언어를 지원하나요?","현재 Moreh Hub는 한국어, 영어 등의 언어로 제공됩니다. 사용자의 국가, 지역, 언어에 따라 일부 기능이 지원되지 않을 수 있으나 향후 기능 지원 범위를 넓혀 나갈 예정입니다.","Q. Moreh Hub를 사용할 때 어떤 서비스 약관이 적용되나요?","Moreh Hub의 AI 모델 사용시에는 Moreh AI Model Hub 콘텐츠 사용 약관이 적용됩니다.","Moreh AI Model Hub **** 서비스 관련 더 자세한 정보에 관한 질문이나 문의사항이 있으시면 contact@moreh.io 로 문의 부탁드립니다."]}],[{"l":"Multi Modal AI"},{"l":"Model Description"},{"i":"예시-chatbot_small","l":"예시: Chatbot_Small","p":["Modality(모델 타입): Text to Text","Training Resource(사용한 GPU 자원): AMD MI250 8 GPU","Training Time(학습 소요 시간)","Model Size: 30B - 35B"]}],[{"l":"Overview"},{"l":"Moreh AI Model Hub Overview","p":["Chatbot Comparison: 동일한 모델에 대한 파라미터 별 학습 시간 및 생성된 답변의 질을 비교하여 각 모델의 성능 차이를 비교할 수 있습니다.","Chatbot_Small, Chatbot_Medium, Chatbot_Large: 챗봇의 명칭은 사용된 언어 모델의 크기에 따라 구분되었습니다. 3개의 챗봇 모두 대형 언어 데이터를 기반으로 문맥을 이해하고 문장을 생성하며 다양한 주제에 대한 정보 제공, 질문 응답, 일상 대화를 통해 사용자와 상호작용합니다.","Code Generator: 사용자가 지정한 규칙 및 요구 사항에 따라, 프로그래밍 코드를 자동으로 생성하여 제공합니다.","Compare Model","Debugging: 입력한 함수를 디버깅 가능한 test case를 작성합니다.","Explain code: 사용자가 입력한 코드가 어떻게 작동하는지 설명합니다.","Generate code: 사용자가 작성한 주석을 수행하는 코드 작성합니다.","Image Generate AI","MAMH 의 목표는 AMD GPU만으로도 학습이 가능한 AI 모델을 사용하고 공유하는 과정을 단순화하고 개선하는 것입니다. 이 서비스는 다음 목적을 충족하기 위해 탄생하였습니다:","Moreh AI Model Hub 는 대규모 모델을 종합적으로 제공하는 서비스로, 언어뿐만 아니라 이미지 생성 및 모델 비교와 같은 다양한 작업을 수행합니다.","Moreh AI Model Hub(MAMH) 작동 방식","Moreh AI Model Hub(MAMH)는 무엇인가요?","Moreh AI Model Hub는 텍스트 및 이미지를 생성하고 언어를 번역하며 다양한 종류의 창의적인 콘텐츠를 작성하는 등의 작업을 하는 도구입니다.","Multi Modal AI","Random Image: 무작위로 선택된 이미지를 제공하는데, 일반적으로 사용자의 요청에 따라 랜덤하게 이미지를 생성합니다.","Text Generate AI","Text to Image Editing: 사용자가 입력한 텍스트 설명에 따라 이미지를 편집합니다.","Text to Image: 텍스트 입력을 기반으로 시각적 콘텐츠를 생성합니다.","Visual Question Answering: 이미지와 관련된 질문에 대답하는 기능을 제공합니다. 사용자가 이미지에 대한 질문을 하면, VQA는 이미지를 분석하고 자연어 처리 기술을 활용하여 해당 질문에 대한 응답을 생성하여 제공합니다.","공동 작업 및 공유: 모델 허브는 사용자 간에 AI 모델을 공동으로 작업하고 공유하는 데 편리한 방법을 제공합니다. 모델을 만들고 수정한 후 다른 사용자와 공유하거나 공동 작업할 수 있습니다. (To Be Determined)","모델 검색 및 선택의 용이성: Model Hub는 하드웨어 자원 및 시간 대비 학습 성능이 좋은 대규모 생성형 AI 모델을 검색하고 선택하는 과정을 단순화합니다. 사용자는 원하는 기능 및 작업에 적합한 모델을 쉽게 찾을 수 있습니다."]},{"i":"moreh-ai-model-hubmamh-사용-방법","l":"Moreh AI Model Hub(MAMH) 사용 방법","p":["좌측 Navigation바에서 MAMH에서 제공하는 모델중 하나를 선택합니다.","Text Generate AI","Chatbot_Small","Chatbot_Medium","Chatbot_Large","Code Generator","Image Generate AI","Text to Image","Random Image","Multi Modal AI","Text to Image Editing","Visual Question Answering","Compare Model","Chatbot Comparison"]}],[{"i":"privacy--terms","l":"Privacy & Terms"},{"l":"Moreh AI Model Hub 콘텐츠 사용 약관","p":["차별적이거나 공격적인 이미지를 생성하거나 업로드하지 마십시오.","악의적이고 공격적인 내용을 담은 콘텐츠","혐오를 조장하거나 부추기는 콘텐츠","폭력, 자해를 조장하는 내용을 담은 콘텐츠","개인을 조롱하거나 위협하거나 괴롭히는 내용을 담은 콘텐츠","특정 집단과 비교하거나 정체성을 기반으로 증오를 표현하거나 조장하는 콘텐츠","AI 생성물에 대해 현혹시키지 마십시오.","Model Hub에서 생성된 콘텐츠를 공유할 때 AI가 작업에 관여한 내용을 투명하게 공개하는 것이 좋습니다.","원하는 경우 Moreh hub 워터마크를 제거할 수 있지만 저작물의 성격에 대해 다른 사람을 오도해서는 안 됩니다. 예를 들어, 해당 작품이 전적으로 인간이 제작한 작품이거나 실제 사건을 그대로 촬영한 사진이라고 해서는 안 됩니다.","타인의 권리를 존중하세요.","동의 없이 타인의 이미지를 업로드하지 마세요.","적절한 사용 권한이 없는 이미지는 업로드하지 마세요.","서비스 이용 및 개인정보 사용 정책"]},{"l":"개인정보 처리 방침","p":["(주)모레 Moreh(이하 \"회사\"라 함)은 개인정보 보호법, 통신비밀보호법, 전기통신사업법, 정보통신망 이용촉진 및 정보보호 등에 관한 법률 등 정보통신서비스제공자가 준수하여야 할 관련 법령상의 개인정보보호 규정을 준수하며, 관련 법령에 의거한 개인정보 처리방침을 정하여 이용자 권익 보호에 최선을 다하고 있습니다."]},{"l":"1. 개인정보의 수집 및 이용목적","p":["개인정보는 생존하는 개인에 관한 정보로서 서비스 이용자를 식별할 수 있는 정보(당해 정보만으로는 특정 개인을 식별할 수 없더라도 다른 정보와 용이하게 결합하여 식별할 수 있는 것을 포함)를 말합니다. Moreh가 수집한 개인정보는 다음의 목적을 위하여 활용하고 있으며, 다음의 목적 이외의 용도로는 이용하지 않습니다.","Moreh Hub에서 이용자 간 주고받은 대화 기록: Moreh Hub에서 귀하가 입력한 내용을 처리하여 적절한 답변과 콘텐츠를 제공하고 이용자에게 맞춤화된 콘텐츠(메시지, 이미지, 오디오 등을 포함)를 제공하는 기본 기능을 제공하기 위해 개인정보를 활용합니다.","브라우징 환경을 모니터링하기 위한 쿠키 및 접속 로그","쿠키 사용을 허용하는 경우 사용자 개인 정보가 명시된 용도로 저장됩니다."]},{"l":"2. 개인정보 보유 및 이용기간","p":["이용자의 개인정보와 가명정보는 원칙적으로 개인정보와 가명정보의 수집 및 이용목적이 달성되면 지체 없이 파기합니다. 단, 다음의 정보에 대해서는 명시한 기간 동안 보존합니다.","방문에 관한 기록 및 쿠키","보존 이유 : 통신비밀보호법","보존 기간 : 3개월","Moreh Hub에서 이용자 간 주고받은 대화 기록","보존 이유: 사용자 경험 향상 및 서비스 성능 고도화 연구를 위한 한시적 보유","보존 기간: 연구 목적 달성 시까지"]}],[{"l":"Image Generate AI","p":["Image Generation"]},{"l":"Text to Image","p":["다음은 Text to Image 에서 시도해 볼 수 있는 프롬프트 예시입니다.","A creative composition of a frog wearing a crown sitting on a log","A 3D rendering of a chair that’s round and red","An illustration of a river winding through a meadow","A photograph of a person sitting on a bench facing the sunset in the style of Van Gogh","Untitled","Screenshot 2023-12-12 at 4.20.16 PM.png"]}],[{"l":"Text Generate AI"},{"l":"1. Text Generate AI"},{"i":"chatbot-small-medium-large","l":"Chatbot (Small, Medium, Large)","p":["하단 Textbox에 프롬프트를 입력하면 MAMH가 학습한 정보를 사용하여 답변을 제공합니다.","다음은 한글/영어 특화 언어 모델을 사용한 Chatbot_Small, Chatbot_Medium, Chatbot_Large에서 시도해 볼 수 있는 몇 가지 프롬프트 예시 입니다.","(한글 프롬프트 예시)","“닭이 먼저야, 달걀이 먼저야?”","“특정 사회 문제를 다루는 비영리 단체를 위한 홍보 캠페인을 계획해줘.”","“단편 소설의 제목을 브레인스토밍하는 데 도움을 줘.”","(영문 프롬프트 예시)","Tell me the best places to travel on a budget of $1000 including car hire, flights and accommodation.","Write a summary of “The catcher in the rye”","Write me a step-by-step guide to use “AI Model Hub”","Generate a list of at least 10 keywords related to Mother nature"]},{"l":"Code Generator","p":["다음은 Code Generator에서 시도해 볼 수 있는 프롬프트 예시입니다.","(영문 프롬프트 예시)","Train a logistic regression model, predict the labels on the test set and compute the accuracy score","Continue writing this code in Python","Generate a function to find the value for (a+b)^3 using lambda.","Generate a Docker script to create a linux machine that has python 3.11.7 installed with following libraries: Pytorch, Tensorflow, Scikit- learn, pandas, numpy.","Generate a unit test for a function that determines if a year is a leap year or not.","(한글 프롬프트 예시)","lambda를 사용하여 (a+b)^ 3의 값을 찾는 함수를 작성해봐.","배열을 인수로 받아 가장 큰 값을 반환하는 함수(함수 이름: findMax) 를 작성해줘.","파이썬 3.11.7이 설치된 Linux 머신을 생성하기 위한 도커 스크립트를 짜줘."]}],[{"l":"Platform Cloud Service"},{"l":"Platform Cloud Service 란","p":["Platfrom Cloud Service (PCS)는 컨테이너화된 애플리케이션을 배포하고 관리하기 위한 확장성이 뛰어난 클라우드 기반 인프라 서비스입니다. Kubernetes라는 오픈소스 컨테이너 플랫폼을 기반으로 하며, 컨테이너화된 애플리케이션을 관리하기 위한 다양한 기능을 제공합니다.","클러스터 관리: Kubernetes 클러스터를 손쉽게 관리할 수 있도록 하며, 필요에 따라 클러스터의 크기를 조정할 수 있습니다.","컨테이너 배포 및 관리: Docker 및 기타 인기 있는 컨테이너 형식을 지원하여 컨테이너를 배포하고 관리할 수 있습니다.","네트워킹 및 스토리지: 로드 밸런싱 및 영구 스토리지와 같은 네트워킹 및 스토리지 옵션을 제공합니다.","모니터링 및 로깅: Prometheus 및 Grafana와 같은 모니터링 및 로깅 툴을 제공합니다."]}]]